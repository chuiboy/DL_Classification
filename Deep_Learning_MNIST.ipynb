{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Deep Learning: Classification\n",
    "___\n",
    "\n",
    "#### Summary:\n",
    "\n",
    "Deep Learning has grown in popularity recently due to better GPUs and the large amount of data we have access to. Combining the large amount of data with better GPUs, we are able to train deep neural networks in a reasonable amount of time that outperform traditional machine learning models such as SVM, Naive Bayes and K-Nearest Neighbor.\n",
    "\n",
    "When building a deep neural network, it is common to use APIs like Tensorflow and Keras. Tensorflow is an API that runs on top of Python, and Keras is an API that runs on top of Tensorflow. When building a neural network, Keras will usually contain all the functions we need.\n",
    "___\n",
    "#### This notebook will include:\n",
    "1. Softmax Regression\n",
    "2. 3-Layer Standard Neural Network (Multilayer Perceptron)\n",
    "3. 8-Layer Standard Neural Network\n",
    "4. 3-Layer Convolutional Network\n",
    "5. 8-Layer Convolutional Network\n",
    "6. Random Forest Classification\n",
    "___\n",
    "#### Reference: \n",
    "\n",
    "Much of what is in this notebook was learned from the Deep Learning Specialization Coursera course by Andrew Ng and from the Tensorflow tutorial at https://www.tensorflow.org/get_started/mnist/pros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "X_train: (55000, 784)\n",
      "y_train: (55000, 10)\n",
      "X_val: (5000, 784)\n",
      "y_val: (5000, 10)\n",
      "X_test: (10000, 784)\n",
      "y_test: (10000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x168a8b00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd7fea58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The dataset that will be used for this notebook is the MNIST dataset which consists of hand-drawn digits \n",
    "ranging from 0 to 9. The dataset is separated into 55000 training examples, 5000 validation examples\n",
    "and 10000 test examples. Each example consists of 784 input features corresponding to the 784 pixel values \n",
    "of the 28x28 sized image. The dataset has already been preprocessed (divided by 255) so there is no need\n",
    "for further preprocessing.\n",
    "\"\"\"\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing the dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "dataset = input_data.read_data_sets(\"Datasets/MNIST/\", one_hot=True)\n",
    "\n",
    "# Printing the dataset shape\n",
    "print('X_train:', dataset.train.images.shape)\n",
    "print('y_train:', dataset.train.labels.shape)\n",
    "print('X_val:', dataset.validation.images.shape)\n",
    "print('y_val:', dataset.validation.labels.shape)\n",
    "print('X_test:', dataset.test.images.shape)\n",
    "print('y_test:', dataset.test.labels.shape)\n",
    "\n",
    "# Displaying an example from the dataset\n",
    "sample = Image.fromarray(255*dataset.train.images[1, :].reshape(28,28))\n",
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 0.12\n",
      "step 100, training accuracy 0.84\n",
      "step 200, training accuracy 0.84\n",
      "step 300, training accuracy 0.89\n",
      "step 400, training accuracy 0.88\n",
      "step 500, training accuracy 0.92\n",
      "step 600, training accuracy 0.89\n",
      "step 700, training accuracy 0.94\n",
      "step 800, training accuracy 0.88\n",
      "step 900, training accuracy 0.91\n",
      "step 1000, training accuracy 0.93\n",
      "step 1100, training accuracy 0.91\n",
      "step 1200, training accuracy 0.92\n",
      "step 1300, training accuracy 0.93\n",
      "step 1400, training accuracy 0.96\n",
      "step 1500, training accuracy 0.89\n",
      "step 1600, training accuracy 0.85\n",
      "step 1700, training accuracy 0.91\n",
      "step 1800, training accuracy 0.94\n",
      "step 1900, training accuracy 0.95\n",
      "step 2000, training accuracy 0.89\n",
      "step 2100, training accuracy 0.93\n",
      "step 2200, training accuracy 0.89\n",
      "step 2300, training accuracy 0.92\n",
      "step 2400, training accuracy 0.91\n",
      "step 2500, training accuracy 0.93\n",
      "step 2600, training accuracy 0.91\n",
      "step 2700, training accuracy 0.97\n",
      "step 2800, training accuracy 0.93\n",
      "step 2900, training accuracy 0.94\n",
      "step 3000, training accuracy 0.96\n",
      "step 3100, training accuracy 0.87\n",
      "step 3200, training accuracy 0.91\n",
      "step 3300, training accuracy 0.92\n",
      "step 3400, training accuracy 0.89\n",
      "step 3500, training accuracy 0.88\n",
      "step 3600, training accuracy 0.99\n",
      "step 3700, training accuracy 0.93\n",
      "step 3800, training accuracy 0.92\n",
      "step 3900, training accuracy 0.89\n",
      "step 4000, training accuracy 0.93\n",
      "step 4100, training accuracy 0.9\n",
      "step 4200, training accuracy 0.92\n",
      "step 4300, training accuracy 0.92\n",
      "step 4400, training accuracy 0.97\n",
      "step 4500, training accuracy 0.91\n",
      "step 4600, training accuracy 0.95\n",
      "step 4700, training accuracy 0.94\n",
      "step 4800, training accuracy 0.95\n",
      "step 4900, training accuracy 0.97\n",
      "step 5000, training accuracy 0.92\n",
      "step 5100, training accuracy 0.93\n",
      "step 5200, training accuracy 0.9\n",
      "step 5300, training accuracy 0.94\n",
      "step 5400, training accuracy 0.89\n",
      "step 5500, training accuracy 0.85\n",
      "step 5600, training accuracy 0.93\n",
      "step 5700, training accuracy 0.88\n",
      "step 5800, training accuracy 0.91\n",
      "step 5900, training accuracy 0.85\n",
      "step 6000, training accuracy 0.91\n",
      "step 6100, training accuracy 0.94\n",
      "step 6200, training accuracy 0.93\n",
      "step 6300, training accuracy 0.98\n",
      "step 6400, training accuracy 0.91\n",
      "step 6500, training accuracy 0.93\n",
      "step 6600, training accuracy 0.91\n",
      "step 6700, training accuracy 0.94\n",
      "step 6800, training accuracy 0.96\n",
      "step 6900, training accuracy 0.9\n",
      "step 7000, training accuracy 0.94\n",
      "step 7100, training accuracy 0.87\n",
      "step 7200, training accuracy 0.91\n",
      "step 7300, training accuracy 0.94\n",
      "step 7400, training accuracy 0.93\n",
      "step 7500, training accuracy 0.91\n",
      "step 7600, training accuracy 0.94\n",
      "step 7700, training accuracy 0.93\n",
      "step 7800, training accuracy 0.89\n",
      "step 7900, training accuracy 0.9\n",
      "step 8000, training accuracy 0.88\n",
      "step 8100, training accuracy 0.94\n",
      "step 8200, training accuracy 0.92\n",
      "step 8300, training accuracy 0.99\n",
      "step 8400, training accuracy 0.93\n",
      "step 8500, training accuracy 0.91\n",
      "step 8600, training accuracy 0.96\n",
      "step 8700, training accuracy 0.93\n",
      "step 8800, training accuracy 0.93\n",
      "step 8900, training accuracy 0.89\n",
      "step 9000, training accuracy 0.92\n",
      "step 9100, training accuracy 0.94\n",
      "step 9200, training accuracy 0.94\n",
      "step 9300, training accuracy 0.9\n",
      "step 9400, training accuracy 0.92\n",
      "step 9500, training accuracy 0.97\n",
      "step 9600, training accuracy 0.91\n",
      "step 9700, training accuracy 0.94\n",
      "step 9800, training accuracy 0.89\n",
      "step 9900, training accuracy 0.92\n",
      "test accuracy 0.9282\n"
     ]
    }
   ],
   "source": [
    "# Softmax regression\n",
    "\"\"\"\n",
    "The simplest classification algorithm for multiple labels is softmax regression. It is a neural network \n",
    "with just 1 layer and hence cannot learn complex features.\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import the data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "dataset = input_data.read_data_sets(\"Datasets/MNIST/\", one_hot=True) #get dataset (one-hot)\n",
    "\n",
    "# Input to model\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# Output of model\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# Parameters\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# Logit\n",
    "Z = tf.matmul(X, W) + b\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=Z)) #Cost\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(Z, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(10000):\n",
    "    batch = dataset.train.next_batch(100)\n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={X: batch[0], y: batch[1]})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "    sess.run(train_step, feed_dict={X: batch[0], y: batch[1]})\n",
    "    \n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={X: dataset.test.images, y: dataset.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "Training accuracy 0.925\n",
      "Test accuracy 0.9226\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine with Gaussian Kernel\n",
    "\"\"\"\n",
    "The SVM classifier with a Gaussian kernel works well for most classification problems, however\n",
    "it is computationally expensive for very large training sets. That is why for this problem we \n",
    "use a subset of the training data.\n",
    "\"\"\"\n",
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn import svm\n",
    "\n",
    "# Import dataset\n",
    "dataset = input_data.read_data_sets(\"Datasets/MNIST/\")\n",
    "\n",
    "#Train on a sample of 10000 training examples (SVM takes long to train with a large training set)\n",
    "X_train_sample, y_train_sample = dataset.train.next_batch(10000)\n",
    "classifier = svm.SVC(kernel = 'rbf', decision_function_shape='ovr')\n",
    "classifier.fit(X_train_sample, y_train_sample) \n",
    "print('Training accuracy %g' % classifier.score(X_train_sample, y_train_sample))\n",
    "\n",
    "# Evaluating the SVM classifier\n",
    "print('Test accuracy %g' % classifier.score(dataset.test.images, dataset.test.labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 0.11\n",
      "step 100, training accuracy 0.68\n",
      "step 200, training accuracy 0.85\n",
      "step 300, training accuracy 0.88\n",
      "step 400, training accuracy 0.83\n",
      "step 500, training accuracy 0.84\n",
      "step 600, training accuracy 0.88\n",
      "step 700, training accuracy 0.85\n",
      "step 800, training accuracy 0.87\n",
      "step 900, training accuracy 0.94\n",
      "step 1000, training accuracy 0.93\n",
      "step 1100, training accuracy 0.98\n",
      "step 1200, training accuracy 0.92\n",
      "step 1300, training accuracy 0.9\n",
      "step 1400, training accuracy 0.93\n",
      "step 1500, training accuracy 0.89\n",
      "step 1600, training accuracy 0.91\n",
      "step 1700, training accuracy 0.97\n",
      "step 1800, training accuracy 0.95\n",
      "step 1900, training accuracy 0.93\n",
      "step 2000, training accuracy 0.88\n",
      "step 2100, training accuracy 0.94\n",
      "step 2200, training accuracy 0.93\n",
      "step 2300, training accuracy 0.96\n",
      "step 2400, training accuracy 0.91\n",
      "step 2500, training accuracy 0.89\n",
      "step 2600, training accuracy 0.85\n",
      "step 2700, training accuracy 0.94\n",
      "step 2800, training accuracy 0.98\n",
      "step 2900, training accuracy 0.94\n",
      "step 3000, training accuracy 0.95\n",
      "step 3100, training accuracy 0.98\n",
      "step 3200, training accuracy 0.98\n",
      "step 3300, training accuracy 0.96\n",
      "step 3400, training accuracy 0.98\n",
      "step 3500, training accuracy 0.96\n",
      "step 3600, training accuracy 0.97\n",
      "step 3700, training accuracy 0.95\n",
      "step 3800, training accuracy 0.99\n",
      "step 3900, training accuracy 0.96\n",
      "step 4000, training accuracy 0.96\n",
      "step 4100, training accuracy 0.95\n",
      "step 4200, training accuracy 0.95\n",
      "step 4300, training accuracy 0.97\n",
      "step 4400, training accuracy 0.95\n",
      "step 4500, training accuracy 0.96\n",
      "step 4600, training accuracy 0.95\n",
      "step 4700, training accuracy 0.97\n",
      "step 4800, training accuracy 0.96\n",
      "step 4900, training accuracy 0.95\n",
      "step 5000, training accuracy 0.95\n",
      "step 5100, training accuracy 0.97\n",
      "step 5200, training accuracy 0.96\n",
      "step 5300, training accuracy 0.93\n",
      "step 5400, training accuracy 0.96\n",
      "step 5500, training accuracy 0.96\n",
      "step 5600, training accuracy 0.98\n",
      "step 5700, training accuracy 0.97\n",
      "step 5800, training accuracy 0.95\n",
      "step 5900, training accuracy 0.93\n",
      "step 6000, training accuracy 0.98\n",
      "step 6100, training accuracy 0.98\n",
      "step 6200, training accuracy 0.96\n",
      "step 6300, training accuracy 0.98\n",
      "step 6400, training accuracy 0.96\n",
      "step 6500, training accuracy 0.98\n",
      "step 6600, training accuracy 1\n",
      "step 6700, training accuracy 0.97\n",
      "step 6800, training accuracy 0.95\n",
      "step 6900, training accuracy 0.95\n",
      "step 7000, training accuracy 0.95\n",
      "step 7100, training accuracy 0.99\n",
      "step 7200, training accuracy 0.99\n",
      "step 7300, training accuracy 0.95\n",
      "step 7400, training accuracy 0.96\n",
      "step 7500, training accuracy 0.97\n",
      "step 7600, training accuracy 0.97\n",
      "step 7700, training accuracy 0.97\n",
      "step 7800, training accuracy 0.99\n",
      "step 7900, training accuracy 0.94\n",
      "step 8000, training accuracy 0.97\n",
      "step 8100, training accuracy 0.96\n",
      "step 8200, training accuracy 0.99\n",
      "step 8300, training accuracy 0.95\n",
      "step 8400, training accuracy 0.97\n",
      "step 8500, training accuracy 0.98\n",
      "step 8600, training accuracy 0.98\n",
      "step 8700, training accuracy 0.95\n",
      "step 8800, training accuracy 0.99\n",
      "step 8900, training accuracy 0.95\n",
      "step 9000, training accuracy 0.99\n",
      "step 9100, training accuracy 0.96\n",
      "step 9200, training accuracy 0.95\n",
      "step 9300, training accuracy 0.97\n",
      "step 9400, training accuracy 0.99\n",
      "step 9500, training accuracy 0.99\n",
      "step 9600, training accuracy 1\n",
      "step 9700, training accuracy 0.95\n",
      "step 9800, training accuracy 0.97\n",
      "step 9900, training accuracy 0.98\n",
      "test accuracy 0.9605\n"
     ]
    }
   ],
   "source": [
    "#Multi-layer FC Neural Network\n",
    "\"\"\"\n",
    "Standard Neural Network with many layers.\n",
    "\"\"\"\n",
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Import dataset\n",
    "dataset = input_data.read_data_sets(\"Datasets/MNIST/\", one_hot=True) #get dataset (one-hot)\n",
    "\n",
    "# Define parameter initialization functions\n",
    "def weight_variable(shape): #symmetry breaking\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape): #avoid dead neurons\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# Create placeholders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#First FC layer (20 hidden units)\n",
    "W_fc1 = weight_variable([784, 20]) #weights between input layer and layer 1 (20 units)\n",
    "b_fc1 = bias_variable([20]) #bias for each hidden unit in layer 1\n",
    "A_fc1 = tf.nn.relu(tf.matmul(X, W_fc1) + b_fc1) #activation of layer 1\n",
    "\n",
    "#Second FC layer (20 hidden units)\n",
    "W_fc2 = weight_variable([20, 20]) #weights between layer 1 and layer 2 (20 units)\n",
    "b_fc2 = bias_variable([20]) #bias for each hidden unit in layer 2\n",
    "A_fc2 = tf.nn.relu(tf.matmul(A_fc1, W_fc2) + b_fc2) #activation of layer 2\n",
    "\n",
    "#Third FC layer (20 hidden units)\n",
    "W_fc3 = weight_variable([20, 20]) #weights between layer 2 and layer 3 (20 units)\n",
    "b_fc3 = bias_variable([20]) #bias for each hidden unit in layer 3\n",
    "A_fc3 = tf.nn.relu(tf.matmul(A_fc2, W_fc3) + b_fc3) #activation of layer 3\n",
    "\n",
    "#Output softmax layer (10 units corresponding to the labels 0-9)\n",
    "W_fc4 = weight_variable([20, 10]) #weights between layer 3 and output layer (10 units)\n",
    "b_fc4 = bias_variable([10]) #bias for each units in output layer\n",
    "Z_fc4 = tf.matmul(A_fc3, W_fc4) + b_fc4\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=Z_fc4)) #Cost\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(Z_fc4, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #accuracy\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(10000):\n",
    "    batch = dataset.train.next_batch(100)\n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={X: batch[0], y: batch[1]})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "    sess.run(train_step, feed_dict={X: batch[0], y: batch[1]})\n",
    "\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={X: dataset.test.images, y: dataset.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 0.12\n",
      "step 100, training accuracy 0.96\n",
      "step 200, training accuracy 1\n",
      "step 300, training accuracy 0.92\n",
      "step 400, training accuracy 0.96\n",
      "step 500, training accuracy 1\n",
      "step 600, training accuracy 0.98\n",
      "step 700, training accuracy 1\n",
      "step 800, training accuracy 1\n",
      "step 900, training accuracy 0.98\n",
      "step 1000, training accuracy 0.96\n",
      "step 1100, training accuracy 1\n",
      "step 1200, training accuracy 0.96\n",
      "step 1300, training accuracy 1\n",
      "step 1400, training accuracy 0.96\n",
      "step 1500, training accuracy 1\n",
      "step 1600, training accuracy 0.98\n",
      "step 1700, training accuracy 1\n",
      "step 1800, training accuracy 1\n",
      "step 1900, training accuracy 1\n",
      "step 2000, training accuracy 0.98\n",
      "step 2100, training accuracy 1\n",
      "step 2200, training accuracy 1\n",
      "step 2300, training accuracy 0.98\n",
      "step 2400, training accuracy 0.98\n",
      "step 2500, training accuracy 1\n",
      "step 2600, training accuracy 1\n",
      "step 2700, training accuracy 1\n",
      "step 2800, training accuracy 0.98\n",
      "step 2900, training accuracy 0.98\n",
      "step 3000, training accuracy 0.94\n",
      "step 3100, training accuracy 1\n",
      "step 3200, training accuracy 1\n",
      "step 3300, training accuracy 1\n",
      "step 3400, training accuracy 0.98\n",
      "step 3500, training accuracy 1\n",
      "step 3600, training accuracy 1\n",
      "step 3700, training accuracy 0.96\n",
      "step 3800, training accuracy 1\n",
      "step 3900, training accuracy 1\n",
      "step 4000, training accuracy 1\n",
      "step 4100, training accuracy 1\n",
      "step 4200, training accuracy 0.98\n",
      "step 4300, training accuracy 1\n",
      "step 4400, training accuracy 0.98\n",
      "step 4500, training accuracy 1\n",
      "step 4600, training accuracy 1\n",
      "step 4700, training accuracy 0.98\n",
      "step 4800, training accuracy 0.98\n",
      "step 4900, training accuracy 1\n",
      "step 5000, training accuracy 1\n",
      "step 5100, training accuracy 1\n",
      "step 5200, training accuracy 1\n",
      "step 5300, training accuracy 1\n",
      "step 5400, training accuracy 1\n",
      "step 5500, training accuracy 1\n",
      "step 5600, training accuracy 1\n",
      "step 5700, training accuracy 1\n",
      "step 5800, training accuracy 1\n",
      "step 5900, training accuracy 1\n",
      "step 6000, training accuracy 0.98\n",
      "step 6100, training accuracy 1\n",
      "step 6200, training accuracy 1\n",
      "step 6300, training accuracy 0.98\n",
      "step 6400, training accuracy 1\n",
      "step 6500, training accuracy 1\n",
      "step 6600, training accuracy 1\n",
      "step 6700, training accuracy 1\n",
      "step 6800, training accuracy 1\n",
      "step 6900, training accuracy 1\n",
      "step 7000, training accuracy 1\n",
      "step 7100, training accuracy 1\n",
      "step 7200, training accuracy 1\n",
      "step 7300, training accuracy 0.98\n",
      "step 7400, training accuracy 1\n",
      "step 7500, training accuracy 0.98\n",
      "step 7600, training accuracy 1\n",
      "step 7700, training accuracy 0.98\n",
      "step 7800, training accuracy 1\n",
      "step 7900, training accuracy 0.98\n",
      "step 8000, training accuracy 1\n",
      "step 8100, training accuracy 1\n",
      "step 8200, training accuracy 0.98\n",
      "step 8300, training accuracy 0.98\n",
      "step 8400, training accuracy 1\n",
      "step 8500, training accuracy 1\n",
      "step 8600, training accuracy 1\n",
      "step 8700, training accuracy 1\n",
      "step 8800, training accuracy 1\n",
      "step 8900, training accuracy 1\n",
      "step 9000, training accuracy 1\n",
      "step 9100, training accuracy 1\n",
      "step 9200, training accuracy 1\n",
      "step 9300, training accuracy 0.98\n",
      "step 9400, training accuracy 0.98\n",
      "step 9500, training accuracy 1\n",
      "step 9600, training accuracy 0.98\n",
      "step 9700, training accuracy 1\n",
      "step 9800, training accuracy 1\n",
      "step 9900, training accuracy 1\n",
      "test accuracy 0.9926\n"
     ]
    }
   ],
   "source": [
    "# Multi-layer CNN\n",
    "\"\"\"\n",
    "A CNN (instead of a standard NN) is used for computer vision tasks because it performs better \n",
    "due to parameter sharing and sparsity of connections. The following example is based on an example from tensorflow.org.\n",
    "\"\"\"\n",
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Import dataset\n",
    "dataset = input_data.read_data_sets(\"Datasets/MNIST/\", one_hot=True) #get dataset (one-hot)\n",
    "\n",
    "# Define parameter initialization functions\n",
    "def weight_variable(shape): #symmetry breaking\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape): #avoid dead neurons\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(X, W): \n",
    "    return tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(X):\n",
    "    return tf.nn.max_pool(X, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#First convolutional layer (32 5x5x1 filters > max-pool)\n",
    "X_image = tf.reshape(X, [-1, 28, 28, 1]) #reshape X to be (#examples, 28, 28, 1)\n",
    "W_conv1 = weight_variable([5, 5, 1, 32]) #32 filters of shape (5,5,1)\n",
    "b_conv1 = bias_variable([32]) #bias for each of the 32 filters\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(X_image, W_conv1) + b_conv1) #(28, 28, 32)\n",
    "h_pool1 = max_pool_2x2(h_conv1) # output of layer (14, 14, 32)\n",
    "\n",
    "#Second convolutional layer (64 5x5x32 filters > max-pool)\n",
    "W_conv2 = weight_variable([5, 5, 32, 64]) #64 filters of shape (5,5,32)\n",
    "b_conv2 = bias_variable([64]) #bias for each of the 64 filters\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) #(14, 14, 64)\n",
    "h_pool2 = max_pool_2x2(h_conv2) #output of layer (7, 7, 64)\n",
    "\n",
    "#Fully-connected layer (1024 hidden units)\n",
    "W_fc1 = weight_variable([7*7*64, 1024]) #1024 hidden units in FC layer\n",
    "b_fc1 = bias_variable([1024]) #biases for the 1024 hidden units\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64]) #reshape output of last convolutional layer to a vector\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1) #output of FC layer (1024)\n",
    "\n",
    "#Dropout regularization applied to FC layer\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#Output softmax layer (10 units corresponding to the labels 0-9)\n",
    "W_fc2 = weight_variable([1024, 10]) #10 units in output layer\n",
    "b_fc2 = bias_variable([10]) #biases for the 10 ouput units\n",
    "\n",
    "Z_fc2 = tf.matmul(h_fc1_drop, W_fc2) + b_fc2 \n",
    "\n",
    "#Training and Evaluation\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=Z_fc2)) #cost\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(Z_fc2, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #accuracy\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(10000):\n",
    "    batch = dataset.train.next_batch(50) \n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={X: batch[0], y: batch[1], keep_prob: 1.0})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={X: batch[0], y: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={X: dataset.test.images, y: dataset.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 0.08\n",
      "step 100, training accuracy 0.78\n",
      "step 200, training accuracy 0.88\n",
      "step 300, training accuracy 0.92\n",
      "step 400, training accuracy 0.92\n",
      "step 500, training accuracy 0.94\n",
      "step 600, training accuracy 0.92\n",
      "step 700, training accuracy 0.98\n",
      "step 800, training accuracy 0.92\n",
      "step 900, training accuracy 0.92\n",
      "step 1000, training accuracy 0.94\n",
      "step 1100, training accuracy 0.94\n",
      "step 1200, training accuracy 0.98\n",
      "step 1300, training accuracy 0.96\n",
      "step 1400, training accuracy 0.96\n",
      "step 1500, training accuracy 0.96\n",
      "step 1600, training accuracy 0.96\n",
      "step 1700, training accuracy 0.98\n",
      "step 1800, training accuracy 0.98\n",
      "step 1900, training accuracy 0.96\n",
      "step 2000, training accuracy 1\n",
      "step 2100, training accuracy 0.96\n",
      "step 2200, training accuracy 0.88\n",
      "step 2300, training accuracy 0.98\n",
      "step 2400, training accuracy 1\n",
      "step 2500, training accuracy 0.96\n",
      "step 2600, training accuracy 0.94\n",
      "step 2700, training accuracy 0.98\n",
      "step 2800, training accuracy 0.96\n",
      "step 2900, training accuracy 0.94\n",
      "step 3000, training accuracy 0.96\n",
      "step 3100, training accuracy 0.98\n",
      "step 3200, training accuracy 1\n",
      "step 3300, training accuracy 0.92\n",
      "step 3400, training accuracy 0.98\n",
      "step 3500, training accuracy 0.98\n",
      "step 3600, training accuracy 0.96\n",
      "step 3700, training accuracy 0.92\n",
      "step 3800, training accuracy 0.96\n",
      "step 3900, training accuracy 1\n",
      "step 4000, training accuracy 0.98\n",
      "step 4100, training accuracy 0.98\n",
      "step 4200, training accuracy 1\n",
      "step 4300, training accuracy 1\n",
      "step 4400, training accuracy 0.98\n",
      "step 4500, training accuracy 0.98\n",
      "step 4600, training accuracy 0.98\n",
      "step 4700, training accuracy 1\n",
      "step 4800, training accuracy 0.96\n",
      "step 4900, training accuracy 1\n",
      "step 5000, training accuracy 0.98\n",
      "step 5100, training accuracy 1\n",
      "step 5200, training accuracy 0.98\n",
      "step 5300, training accuracy 0.98\n",
      "step 5400, training accuracy 0.98\n",
      "step 5500, training accuracy 1\n",
      "step 5600, training accuracy 1\n",
      "step 5700, training accuracy 1\n",
      "step 5800, training accuracy 0.96\n",
      "step 5900, training accuracy 1\n",
      "step 6000, training accuracy 1\n",
      "step 6100, training accuracy 0.98\n",
      "step 6200, training accuracy 1\n",
      "step 6300, training accuracy 0.96\n",
      "step 6400, training accuracy 1\n",
      "step 6500, training accuracy 0.98\n",
      "step 6600, training accuracy 0.98\n",
      "step 6700, training accuracy 0.98\n",
      "step 6800, training accuracy 1\n",
      "step 6900, training accuracy 1\n",
      "step 7000, training accuracy 1\n",
      "step 7100, training accuracy 1\n",
      "step 7200, training accuracy 1\n",
      "step 7300, training accuracy 0.98\n",
      "step 7400, training accuracy 1\n",
      "step 7500, training accuracy 1\n",
      "step 7600, training accuracy 0.98\n",
      "step 7700, training accuracy 0.98\n",
      "step 7800, training accuracy 0.98\n",
      "step 7900, training accuracy 0.98\n",
      "step 8000, training accuracy 0.98\n",
      "step 8100, training accuracy 1\n",
      "step 8200, training accuracy 1\n",
      "step 8300, training accuracy 0.96\n",
      "step 8400, training accuracy 1\n",
      "step 8500, training accuracy 1\n",
      "step 8600, training accuracy 1\n",
      "step 8700, training accuracy 0.96\n",
      "step 8800, training accuracy 1\n",
      "step 8900, training accuracy 1\n",
      "step 9000, training accuracy 1\n",
      "step 9100, training accuracy 1\n",
      "step 9200, training accuracy 0.98\n",
      "step 9300, training accuracy 1\n",
      "step 9400, training accuracy 1\n",
      "step 9500, training accuracy 1\n",
      "step 9600, training accuracy 0.98\n",
      "step 9700, training accuracy 1\n",
      "step 9800, training accuracy 1\n",
      "step 9900, training accuracy 1\n",
      "test accuracy 0.9909\n"
     ]
    }
   ],
   "source": [
    "# LeNet-5\n",
    "\"\"\"\n",
    "The LeNet-5 is just a multi-layer CNN with its own set of hyperparameters.\n",
    "\"\"\"\n",
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Import dataset\n",
    "dataset = input_data.read_data_sets(\"Datasets/MNIST/\", one_hot=True) #get dataset (one-hot)\n",
    "\n",
    "# Define parameter initialization functions\n",
    "def weight_variable(shape): #symmetry breaking\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape): #avoid dead neurons\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(X, W):\n",
    "    return tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "def avg_pool_2x2(X):\n",
    "    return tf.nn.avg_pool(X, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#First convolutional layer (6 5x5x1 filters > average-pool)\n",
    "X_image = tf.reshape(X, [-1, 28, 28, 1]) #reshape X to be (#examples, 28, 28, 1)\n",
    "W_conv1 = weight_variable([5, 5, 1, 6]) #6 filters of shape (5,5,1)\n",
    "b_conv1 = bias_variable([6]) #bias for each of the 6 filters\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(X_image, W_conv1) + b_conv1) #(24, 24, 6)\n",
    "h_pool1 = avg_pool_2x2(h_conv1) # output of layer (12, 12, 6)\n",
    "\n",
    "#Second convolutional layer (16 5x5x6 filters > average-pool)\n",
    "W_conv2 = weight_variable([5, 5, 6, 16]) #16 filters of shape (5,5,6)\n",
    "b_conv2 = bias_variable([16]) #bias for each of the 16 filters\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) #(8, 8, 16)\n",
    "h_pool2 = avg_pool_2x2(h_conv2) #output of layer (4, 4, 16)\n",
    "\n",
    "#First fully-connected layer (120 hidden units)\n",
    "W_fc1 = weight_variable([4*4*16, 120]) #120 hidden units in first FC layer\n",
    "b_fc1 = bias_variable([120]) #biases for the 120 hidden units\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 4*4*16]) #reshape output of last convolutional layer to a vector\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1) #output of FC layer (120)\n",
    "\n",
    "#Second fully-connected layer (84 hidden units)\n",
    "W_fc2 = weight_variable([120, 84]) #84 hidden units in second FC layer\n",
    "b_fc2 = bias_variable([84]) #biases for the 84 hidden units\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2) #output of FC layer (84)\n",
    "\n",
    "#Dropout regularization applied to second FC layer\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "\n",
    "#Output softmax layer (10 units corresponding to the labels 0-9)\n",
    "W_fc3 = weight_variable([84, 10]) #10 units in output layer\n",
    "b_fc3 = bias_variable([10]) #biases for the 10 ouput units\n",
    "\n",
    "Z_fc3 = tf.matmul(h_fc2_drop, W_fc3) + b_fc3 \n",
    "\n",
    "#Training and Evaluation\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=Z_fc3)) #cost\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(Z_fc3, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #accuracy\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(10000):\n",
    "    batch = dataset.train.next_batch(50) \n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={X: batch[0], y: batch[1], keep_prob: 1.0})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={X: batch[0], y: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={X: dataset.test.images, y: dataset.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 0.1\n",
      "step 100, training accuracy 0.68\n",
      "step 200, training accuracy 0.94\n",
      "step 300, training accuracy 1\n",
      "step 400, training accuracy 0.92\n",
      "step 500, training accuracy 0.94\n",
      "step 600, training accuracy 0.92\n",
      "step 700, training accuracy 0.98\n",
      "step 800, training accuracy 0.92\n",
      "step 900, training accuracy 0.92\n",
      "step 1000, training accuracy 0.92\n",
      "step 1100, training accuracy 0.96\n",
      "step 1200, training accuracy 0.9\n",
      "step 1300, training accuracy 0.96\n",
      "step 1400, training accuracy 0.96\n",
      "step 1500, training accuracy 0.94\n",
      "step 1600, training accuracy 1\n",
      "step 1700, training accuracy 0.98\n",
      "step 1800, training accuracy 0.94\n",
      "step 1900, training accuracy 0.96\n",
      "step 2000, training accuracy 0.98\n",
      "step 2100, training accuracy 0.98\n",
      "step 2200, training accuracy 0.98\n",
      "step 2300, training accuracy 0.98\n",
      "step 2400, training accuracy 0.94\n",
      "step 2500, training accuracy 0.98\n",
      "step 2600, training accuracy 0.98\n",
      "step 2700, training accuracy 0.98\n",
      "step 2800, training accuracy 0.98\n",
      "step 2900, training accuracy 0.96\n",
      "step 3000, training accuracy 0.98\n",
      "step 3100, training accuracy 0.94\n",
      "step 3200, training accuracy 0.96\n",
      "step 3300, training accuracy 0.96\n",
      "step 3400, training accuracy 1\n",
      "step 3500, training accuracy 0.98\n",
      "step 3600, training accuracy 0.96\n",
      "step 3700, training accuracy 1\n",
      "step 3800, training accuracy 1\n",
      "step 3900, training accuracy 1\n",
      "step 4000, training accuracy 0.94\n",
      "step 4100, training accuracy 0.98\n",
      "step 4200, training accuracy 1\n",
      "step 4300, training accuracy 0.98\n",
      "step 4400, training accuracy 1\n",
      "step 4500, training accuracy 1\n",
      "step 4600, training accuracy 1\n",
      "step 4700, training accuracy 0.94\n",
      "step 4800, training accuracy 1\n",
      "step 4900, training accuracy 0.98\n",
      "step 5000, training accuracy 0.98\n",
      "step 5100, training accuracy 1\n",
      "step 5200, training accuracy 0.98\n",
      "step 5300, training accuracy 0.98\n",
      "step 5400, training accuracy 0.96\n",
      "step 5500, training accuracy 0.96\n",
      "step 5600, training accuracy 1\n",
      "step 5700, training accuracy 0.98\n",
      "step 5800, training accuracy 0.94\n",
      "step 5900, training accuracy 0.96\n",
      "step 6000, training accuracy 0.98\n",
      "step 6100, training accuracy 1\n",
      "step 6200, training accuracy 1\n",
      "step 6300, training accuracy 1\n",
      "step 6400, training accuracy 0.98\n",
      "step 6500, training accuracy 0.98\n",
      "step 6600, training accuracy 0.98\n",
      "step 6700, training accuracy 1\n",
      "step 6800, training accuracy 1\n",
      "step 6900, training accuracy 0.94\n",
      "step 7000, training accuracy 0.94\n",
      "step 7100, training accuracy 1\n",
      "step 7200, training accuracy 1\n",
      "step 7300, training accuracy 0.94\n",
      "step 7400, training accuracy 0.98\n",
      "step 7500, training accuracy 1\n",
      "step 7600, training accuracy 0.98\n",
      "step 7700, training accuracy 0.98\n",
      "step 7800, training accuracy 0.98\n",
      "step 7900, training accuracy 1\n",
      "step 8000, training accuracy 0.96\n",
      "step 8100, training accuracy 1\n",
      "step 8200, training accuracy 1\n",
      "step 8300, training accuracy 1\n",
      "step 8400, training accuracy 1\n",
      "step 8500, training accuracy 1\n",
      "step 8600, training accuracy 1\n",
      "step 8700, training accuracy 1\n",
      "step 8800, training accuracy 1\n",
      "step 8900, training accuracy 0.96\n",
      "step 9000, training accuracy 1\n",
      "step 9100, training accuracy 1\n",
      "step 9200, training accuracy 0.96\n",
      "step 9300, training accuracy 1\n",
      "step 9400, training accuracy 0.98\n",
      "step 9500, training accuracy 0.98\n",
      "step 9600, training accuracy 0.98\n",
      "step 9700, training accuracy 0.98\n",
      "step 9800, training accuracy 0.98\n",
      "step 9900, training accuracy 1\n",
      "test accuracy 0.9803\n"
     ]
    }
   ],
   "source": [
    "# Residual Network\n",
    "\"\"\"\n",
    "A ResNet is a series of convolutional and identity blocks. It helps prevent exploding/vanishing gradients that \n",
    "often result from a very deep CNN. A ResNet is typically used for much deeper networks than the one below and \n",
    "it usually includes pooling layers as well. We apply a ResNet here just to show how it works.\n",
    "\"\"\"\n",
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Import dataset\n",
    "dataset = input_data.read_data_sets(\"Datasets/MNIST/\", one_hot=True) #get dataset (one-hot)\n",
    "\n",
    "# Define parameter initialization functions\n",
    "def weight_variable(shape): #symmetry breaking\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# Define identity block function\n",
    "def identity_block(X, f, filters): #Use when the output dimension matches input dimension\n",
    "    F1, F2, F3 = filters\n",
    "    W_conv1 = weight_variable([1, 1, F3, F1]) #F1 filters of shape (1,1,F3)\n",
    "    h_conv1 = tf.nn.relu(tf.layers.batch_normalization(\n",
    "            tf.nn.conv2d(X, W_conv1, strides=[1, 1, 1, 1], padding='VALID'), axis=2))\n",
    "    W_conv2 = weight_variable([f, f, F1, F2]) #F2 filters of shape (f,f,F1)\n",
    "    h_conv2 = tf.nn.relu(tf.layers.batch_normalization(\n",
    "            tf.nn.conv2d(h_conv1, W_conv2, strides=[1, 1, 1, 1], padding='SAME'), axis=2)) \n",
    "    W_conv3 = weight_variable([1, 1, F2, F3]) #F3 filters of shape (1,1,F2)\n",
    "    h_conv3 = tf.nn.relu(tf.layers.batch_normalization(\n",
    "            tf.nn.conv2d(h_conv2, W_conv3, strides=[1, 1, 1, 1], padding='VALID'), axis=2) + X)\n",
    "            #F3 = number channels in X\n",
    "    return h_conv3\n",
    "\n",
    "# Define convolutional block function\n",
    "def convolutional_block(X, f, filters, s = 2): #Use when the output dimension does not match input dimension\n",
    "    F1, F2, F3 = filters\n",
    "    X_channels = tf.constant(X.get_shape()[3].value) #number of channels\n",
    "    \n",
    "    W_conv1 = weight_variable([1, 1, X_channels, F1]) #F1 filters of shape (1,1,X_channels)\n",
    "    h_conv1 = tf.nn.relu(tf.layers.batch_normalization(\n",
    "            tf.nn.conv2d(X, W_conv1, strides=[1, s, s, 1], padding='VALID'), axis=2)) \n",
    "    W_conv2 = weight_variable([f, f, F1, F2]) #F2 filters of shape (f,f,F1)\n",
    "    h_conv2 = tf.nn.relu(tf.layers.batch_normalization(\n",
    "            tf.nn.conv2d(h_conv1, W_conv2, strides=[1, 1, 1, 1], padding='SAME'), axis=2)) \n",
    "    W_conv3 = weight_variable([1, 1, F2, F3]) #F3 filters of shape (1,1,F2)\n",
    "    z_conv3 = tf.layers.batch_normalization(\n",
    "            tf.nn.conv2d(h_conv2, W_conv3, strides=[1, 1, 1, 1], padding='VALID'), axis=2) \n",
    "    W_shortcut = weight_variable([1, 1, X_channels, F3]) #F3 filters of shape (1,1,X_channels)\n",
    "    z_shortcut = tf.layers.batch_normalization(\n",
    "            tf.nn.conv2d(X, W_shortcut, strides=[1, s, s, 1], padding='VALID'), axis=2) \n",
    "    h_conv3 = tf.nn.relu(z_conv3 + z_shortcut) \n",
    "    \n",
    "    return h_conv3\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "X_image = tf.reshape(X, [-1, 28, 28, 1]) #reshape X to be (#examples, 28, 28, 1)\n",
    "\n",
    "block1 = convolutional_block(X_image, f = 5, filters = [6, 6, 6]) #(14,14,6)\n",
    "block2 = identity_block(block1, f = 5, filters = [6, 6, 6]) #(14,14,6)\n",
    "block3 = identity_block(block2, f = 5, filters = [6, 6, 6]) #(14,14,6)\n",
    "block4 = identity_block(block3, f = 5, filters = [6, 6, 6]) #(14,14,6)\n",
    "block5 = convolutional_block(block4, f = 5, filters = [12, 12, 12]) #(7,7,12)\n",
    "block6 = identity_block(block5, f = 5, filters = [12, 12, 12]) #(7,7,12)\n",
    "block7 = identity_block(block6, f = 5, filters = [12, 12, 12]) #(7,7,12)\n",
    "block8 = identity_block(block7, f = 5, filters = [12, 12, 12]) #(7,7,12)\n",
    "\n",
    "#Output softmax layer (10 units corresponding to the labels 0-9)\n",
    "W_fc1 = weight_variable([7*7*12, 10])\n",
    "block8_flat = tf.reshape(block8, [-1, 7*7*12]) #reshape output of last convolutional layer to a vector\n",
    "\n",
    "Z_fc1 = tf.matmul(block8_flat, W_fc1)\n",
    "\n",
    "#Training and Evaluation\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=Z_fc1)) #cost\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(Z_fc1, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #accuracy\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(10000):\n",
    "    batch = dataset.train.next_batch(50) \n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={X: batch[0], y: batch[1]})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={X: batch[0], y: batch[1]})\n",
    "\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={X: dataset.test.images, y: dataset.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 0.04\n",
      "step 100, training accuracy 0.78\n",
      "step 200, training accuracy 0.96\n",
      "step 300, training accuracy 0.92\n",
      "step 400, training accuracy 0.88\n",
      "step 500, training accuracy 0.94\n",
      "step 600, training accuracy 0.94\n",
      "step 700, training accuracy 0.96\n",
      "step 800, training accuracy 0.94\n",
      "step 900, training accuracy 0.94\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,28,28,96]\n\t [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, Variable_2/read)]]\n\t [[Node: Mean_1/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_215_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Conv2D_1', defined at:\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 592, in launch_instance\n    app.start()\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 403, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 151, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-66006edd0f15>\", line 62, in <module>\n    block1 = inception_block(X_image)\n  File \"<ipython-input-1-66006edd0f15>\", line 36, in inception_block\n    h_conv2_1 = tf.nn.relu(tf.nn.conv2d(X, W_conv2_1, strides=[1, 1, 1, 1], padding='VALID') + b_conv2_1)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 630, in conv2d\n    data_format=data_format, name=name)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,28,28,96]\n\t [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, Variable_2/read)]]\n\t [[Node: Mean_1/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_215_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,28,28,96]\n\t [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, Variable_2/read)]]\n\t [[Node: Mean_1/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_215_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-66006edd0f15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[0mtrain_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test accuracy %g'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m     \"\"\"\n\u001b[1;32m--> 570\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_dup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   4453\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4454\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 4455\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,28,28,96]\n\t [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, Variable_2/read)]]\n\t [[Node: Mean_1/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_215_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Conv2D_1', defined at:\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 592, in launch_instance\n    app.start()\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 403, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 151, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-66006edd0f15>\", line 62, in <module>\n    block1 = inception_block(X_image)\n  File \"<ipython-input-1-66006edd0f15>\", line 36, in inception_block\n    h_conv2_1 = tf.nn.relu(tf.nn.conv2d(X, W_conv2_1, strides=[1, 1, 1, 1], padding='VALID') + b_conv2_1)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 630, in conv2d\n    data_format=data_format, name=name)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,28,28,96]\n\t [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, Variable_2/read)]]\n\t [[Node: Mean_1/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_215_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# Inception Network\n",
    "\"\"\"\n",
    "An inception network lets the network choose which filters to use. It is composed of many \n",
    "inception blocks. Each inception block consists of many different convolutions applied to an input\n",
    "and the output is the concatenation of these convolutions. The network below consists of just two\n",
    "inception blocks. Typically an inception network also includes other layers outside of the inception block.\n",
    "The Google Inception Network is an example.\n",
    "\n",
    "NOTE: This network requires more memory than I have available. An example of an inception network with fewer\n",
    "parameters is shown in the cell below.\n",
    "\"\"\"\n",
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Import dataset\n",
    "dataset = input_data.read_data_sets(\"Datasets/MNIST/\", one_hot=True) #get dataset (one-hot)\n",
    "\n",
    "# Define parameter initialization functions\n",
    "def weight_variable(shape): #symmetry breaking\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape): #avoid dead neurons\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def inception_block(X):\n",
    "    X_channels = tf.constant(X.get_shape()[3].value) #number of channels\n",
    "    \n",
    "    W_conv1_1 = weight_variable([1, 1, X_channels, 64]) #64 filters of shape (1,1,X_channels)\n",
    "    b_conv1_1 = bias_variable([64])\n",
    "    h_conv1_1 = tf.nn.relu(tf.nn.conv2d(X, W_conv1_1, strides=[1, 1, 1, 1], padding='VALID') + b_conv1_1)\n",
    "    \n",
    "    W_conv2_1 = weight_variable([1, 1, X_channels, 96]) #96 filters of shape (1,1,X_channels)\n",
    "    b_conv2_1 = bias_variable([96])\n",
    "    h_conv2_1 = tf.nn.relu(tf.nn.conv2d(X, W_conv2_1, strides=[1, 1, 1, 1], padding='VALID') + b_conv2_1)\n",
    "    W_conv2_2 = weight_variable([3, 3, 96, 128]) #128 filters of shape (3,3,96)\n",
    "    b_conv2_2 = bias_variable([128])\n",
    "    h_conv2_2 = tf.nn.relu(tf.nn.conv2d(h_conv2_1, W_conv2_2, strides=[1, 1, 1, 1], padding='SAME') + b_conv2_2)\n",
    "    \n",
    "    W_conv3_1 = weight_variable([1, 1, X_channels, 16]) #16 filters of shape (1,1,X_channels)\n",
    "    b_conv3_1 = bias_variable([16])\n",
    "    h_conv3_1 = tf.nn.relu(tf.nn.conv2d(X, W_conv3_1, strides=[1, 1, 1, 1], padding='VALID') + b_conv3_1)\n",
    "    W_conv3_2 = weight_variable([5, 5, 16, 32]) #32 filters of shape (5,5,16)\n",
    "    b_conv3_2 = bias_variable([32])\n",
    "    h_conv3_2 = tf.nn.relu(tf.nn.conv2d(h_conv3_1, W_conv3_2, strides=[1, 1, 1, 1], padding='SAME') + b_conv3_2)\n",
    "    \n",
    "    h_pool4 = tf.nn.max_pool(X, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding='SAME')\n",
    "    W_conv4_1 = weight_variable([1, 1, X_channels, 32]) #32 filters of shape (1,1,X_channels)\n",
    "    b_conv4_1 = bias_variable([32])\n",
    "    h_conv4_1 = tf.nn.relu(tf.nn.conv2d(h_pool4, W_conv4_1, strides=[1, 1, 1, 1], padding='VALID') + b_conv4_1)\n",
    "    \n",
    "    h_conv5 = tf.concat([h_conv1_1, h_conv2_2, h_conv3_2, h_conv4_1], 3)\n",
    "    \n",
    "    return h_conv5\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "X_image = tf.reshape(X, [-1, 28, 28, 1]) #reshape X to be (#examples, 28, 28, 1)\n",
    "\n",
    "block1 = inception_block(X_image)\n",
    "block2 = inception_block(block1)\n",
    "block3 = inception_block(block2)\n",
    "\n",
    "# Output softmax layer (10 units corresponding to the labels 0-9)\n",
    "W_fc1 = weight_variable([28*28*256, 10])\n",
    "b_fc1 = bias_variable([10])\n",
    "block3_flat = tf.reshape(block3, [-1, 28*28*256]) #reshape output of last convolutional layer to a vector\n",
    "\n",
    "Z_fc1 = tf.matmul(block3_flat, W_fc1) + b_fc1\n",
    "\n",
    "# Training and Evaluation\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=Z_fc1)) #cost\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(Z_fc1, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #accuracy\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(1000):\n",
    "    batch = dataset.train.next_batch(50) \n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={X: batch[0], y: batch[1]})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={X: batch[0], y: batch[1]})\n",
    "\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={X: dataset.test.images, y: dataset.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 0.18\n",
      "step 100, training accuracy 0.5\n",
      "step 200, training accuracy 0.88\n",
      "step 300, training accuracy 0.96\n",
      "step 400, training accuracy 0.9\n",
      "step 500, training accuracy 0.96\n",
      "step 600, training accuracy 0.92\n",
      "step 700, training accuracy 0.98\n",
      "step 800, training accuracy 0.92\n",
      "step 900, training accuracy 0.98\n",
      "step 1000, training accuracy 0.94\n",
      "step 1100, training accuracy 1\n",
      "step 1200, training accuracy 1\n",
      "step 1300, training accuracy 0.96\n",
      "step 1400, training accuracy 0.94\n",
      "step 1500, training accuracy 0.88\n",
      "step 1600, training accuracy 0.98\n",
      "step 1700, training accuracy 1\n",
      "step 1800, training accuracy 0.98\n",
      "step 1900, training accuracy 1\n",
      "step 2000, training accuracy 1\n",
      "step 2100, training accuracy 1\n",
      "step 2200, training accuracy 1\n",
      "step 2300, training accuracy 0.98\n",
      "step 2400, training accuracy 1\n",
      "step 2500, training accuracy 0.98\n",
      "step 2600, training accuracy 1\n",
      "step 2700, training accuracy 1\n",
      "step 2800, training accuracy 0.98\n",
      "step 2900, training accuracy 1\n",
      "step 3000, training accuracy 0.98\n",
      "step 3100, training accuracy 0.98\n",
      "step 3200, training accuracy 0.94\n",
      "step 3300, training accuracy 0.96\n",
      "step 3400, training accuracy 0.98\n",
      "step 3500, training accuracy 1\n",
      "step 3600, training accuracy 0.98\n",
      "step 3700, training accuracy 0.96\n",
      "step 3800, training accuracy 1\n",
      "step 3900, training accuracy 1\n",
      "step 4000, training accuracy 0.98\n",
      "step 4100, training accuracy 1\n",
      "step 4200, training accuracy 1\n",
      "step 4300, training accuracy 1\n",
      "step 4400, training accuracy 1\n",
      "step 4500, training accuracy 1\n",
      "step 4600, training accuracy 1\n",
      "step 4700, training accuracy 1\n",
      "step 4800, training accuracy 0.98\n",
      "step 4900, training accuracy 1\n",
      "step 5000, training accuracy 0.96\n",
      "step 5100, training accuracy 1\n",
      "step 5200, training accuracy 0.98\n",
      "step 5300, training accuracy 0.98\n",
      "step 5400, training accuracy 0.96\n",
      "step 5500, training accuracy 0.98\n",
      "step 5600, training accuracy 1\n",
      "step 5700, training accuracy 1\n",
      "step 5800, training accuracy 1\n",
      "step 5900, training accuracy 1\n",
      "step 6000, training accuracy 1\n",
      "step 6100, training accuracy 1\n",
      "step 6200, training accuracy 1\n",
      "step 6300, training accuracy 1\n",
      "step 6400, training accuracy 0.98\n",
      "step 6500, training accuracy 0.98\n",
      "step 6600, training accuracy 1\n",
      "step 6700, training accuracy 1\n",
      "step 6800, training accuracy 1\n",
      "step 6900, training accuracy 1\n",
      "step 7000, training accuracy 0.98\n",
      "step 7100, training accuracy 1\n",
      "step 7200, training accuracy 0.96\n",
      "step 7300, training accuracy 1\n",
      "step 7400, training accuracy 0.98\n",
      "step 7500, training accuracy 1\n",
      "step 7600, training accuracy 0.96\n",
      "step 7700, training accuracy 1\n",
      "step 7800, training accuracy 1\n",
      "step 7900, training accuracy 1\n",
      "step 8000, training accuracy 1\n",
      "step 8100, training accuracy 1\n",
      "step 8200, training accuracy 1\n",
      "step 8300, training accuracy 0.98\n",
      "step 8400, training accuracy 0.98\n",
      "step 8500, training accuracy 1\n",
      "step 8600, training accuracy 1\n",
      "step 8700, training accuracy 1\n",
      "step 8800, training accuracy 0.94\n",
      "step 8900, training accuracy 1\n",
      "step 9000, training accuracy 1\n",
      "step 9100, training accuracy 1\n",
      "step 9200, training accuracy 1\n",
      "step 9300, training accuracy 1\n",
      "step 9400, training accuracy 1\n",
      "step 9500, training accuracy 1\n",
      "step 9600, training accuracy 1\n",
      "step 9700, training accuracy 1\n",
      "step 9800, training accuracy 1\n",
      "step 9900, training accuracy 1\n",
      "test accuracy 0.9853\n"
     ]
    }
   ],
   "source": [
    "# Inception Network\n",
    "\"\"\"\n",
    "Simpler inception network.\n",
    "\n",
    "\"\"\"\n",
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Import dataset\n",
    "dataset = input_data.read_data_sets(\"Datasets/MNIST/\", one_hot=True) #get dataset (one-hot)\n",
    "\n",
    "# Define parameter initialization functions\n",
    "def weight_variable(shape): #symmetry breaking\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape): #avoid dead neurons\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# Define inception block function\n",
    "def inception_block(X):\n",
    "    X_channels = tf.constant(X.get_shape()[3].value) #number of channels\n",
    "    \n",
    "    W_conv1_1 = weight_variable([1, 1, X_channels, 6]) #6 filters of shape (1,1,X_channels)\n",
    "    b_conv1_1 = bias_variable([6])\n",
    "    h_conv1_1 = tf.nn.relu(tf.nn.conv2d(X, W_conv1_1, strides=[1, 1, 1, 1], padding='VALID') + b_conv1_1)\n",
    "    \n",
    "    W_conv2_1 = weight_variable([1, 1, X_channels, 6]) #6 filters of shape (1,1,X_channels)\n",
    "    b_conv2_1 = bias_variable([6])\n",
    "    h_conv2_1 = tf.nn.relu(tf.nn.conv2d(X, W_conv2_1, strides=[1, 1, 1, 1], padding='VALID') + b_conv2_1)\n",
    "    W_conv2_2 = weight_variable([3, 3, 6, 6]) #8 filters of shape (3,3,6)\n",
    "    b_conv2_2 = bias_variable([6])\n",
    "    h_conv2_2 = tf.nn.relu(tf.nn.conv2d(h_conv2_1, W_conv2_2, strides=[1, 1, 1, 1], padding='SAME') + b_conv2_2)   \n",
    "\n",
    "    W_conv3_1 = weight_variable([1, 1, X_channels, 6]) #6 filters of shape (1,1,X_channels)\n",
    "    b_conv3_1 = bias_variable([6])\n",
    "    h_conv3_1 = tf.nn.relu(tf.nn.conv2d(X, W_conv3_1, strides=[1, 1, 1, 1], padding='VALID') + b_conv3_1)\n",
    "    W_conv3_2 = weight_variable([5, 5, 6, 6]) #6 filters of shape (5,5,6)\n",
    "    b_conv3_2 = bias_variable([6])\n",
    "    h_conv3_2 = tf.nn.relu(tf.nn.conv2d(h_conv3_1, W_conv3_2, strides=[1, 1, 1, 1], padding='SAME') + b_conv3_2)\n",
    "    \n",
    "    h_pool4 = tf.nn.max_pool(X, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding='SAME')\n",
    "    W_conv4_1 = weight_variable([1, 1, X_channels, 6]) #6 filters of shape (1,1,X_channels)\n",
    "    b_conv4_1 = bias_variable([6])\n",
    "    h_conv4_1 = tf.nn.relu(tf.nn.conv2d(h_pool4, W_conv4_1, strides=[1, 1, 1, 1], padding='VALID') + b_conv4_1)\n",
    "    \n",
    "    h_conv5 = tf.concat([h_conv1_1, h_conv2_2, h_conv3_2, h_conv4_1], 3)\n",
    "    \n",
    "    return h_conv5\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "X_image = tf.reshape(X, [-1, 28, 28, 1]) #reshape X to be (#examples, 28, 28, 1)\n",
    "\n",
    "block1 = inception_block(X_image)\n",
    "block2 = inception_block(block1)\n",
    "block3 = inception_block(block2)\n",
    "\n",
    "#Output softmax layer (10 units corresponding to the labels 0-9)\n",
    "W_fc1 = weight_variable([28*28*24, 10])\n",
    "b_fc1 = bias_variable([10])\n",
    "block3_flat = tf.reshape(block3, [-1, 28*28*24]) #reshape output of last convolutional layer to a vector\n",
    "\n",
    "Z_fc1 = tf.matmul(block3_flat, W_fc1) + b_fc1\n",
    "\n",
    "#Training and Evaluation\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=Z_fc1)) #cost\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(Z_fc1, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #accuracy\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(10000):\n",
    "    batch = dataset.train.next_batch(50) \n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={X: batch[0], y: batch[1]})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={X: batch[0], y: batch[1]})\n",
    "\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={X: dataset.test.images, y: dataset.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
