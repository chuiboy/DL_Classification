{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Deep Learning: Classification\n",
    "___\n",
    "\n",
    "#### Summary:\n",
    "\n",
    "Deep Learning has grown in popularity recently due to better GPUs and the large amount of data we have access to. Combining the large amount of data with better GPUs, we are able to train deep neural networks in a reasonable amount of time that outperform traditional machine learning models such as SVM, Naive Bayes and K-Nearest Neighbor.\n",
    "\n",
    "When building a deep neural network, it is common to use APIs like Tensorflow and Keras. Tensorflow is an API that runs on top of Python, and Keras is an API that runs on top of Tensorflow. When building a neural network, Keras will usually contain all the tools we need. Note that there we will not get into hyperparameter tuning here and will not use the validation set (The test set is used as the validaiton set here).\n",
    "___\n",
    "#### This notebook will include:\n",
    "1. Softmax Regression\n",
    "2. Support Vector Machine\n",
    "3. 3-Layer Standard Neural Network (Multilayer Perceptron)\n",
    "4. 8-Layer Standard Neural Network\n",
    "5. 3-Layer Convolutional Network\n",
    "6. 8-Layer Convolutional Network\n",
    "7. Inception Network\n",
    "8. Residual Network\n",
    "___\n",
    "#### Reference: \n",
    "\n",
    "Much of what is in this notebook was learned from the Deep Learning Specialization Coursera course by Andrew Ng and from the Tensorflow tutorial at https://www.tensorflow.org/get_started/mnist/pros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "X_train: (55000, 784)\n",
      "y_train: (55000,)\n",
      "X_val: (5000, 784)\n",
      "y_val: (5000,)\n",
      "X_test: (10000, 784)\n",
      "y_test: (10000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x223c54e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21d74f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The dataset that will be used for this notebook is the MNIST dataset which consists of hand-drawn digits\n",
    "ranging from 0 to 9. The dataset is separated into 55000 training examples, 5000 validation examples\n",
    "and 10000 test examples. Each example consists of 784 input features corresponding to the 784 pixel \n",
    "values of the 28x28 sized image. The dataset has already been preprocessed (divided by 255).\n",
    "\"\"\"\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing the dataset (not one-hot encoded)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "dataset = input_data.read_data_sets(\"Datasets/MNIST/\", one_hot=False)\n",
    "\n",
    "X_train = dataset.train.images\n",
    "y_train = dataset.train.labels\n",
    "X_val = dataset.validation.images\n",
    "y_val = dataset.validation.labels\n",
    "X_test = dataset.test.images\n",
    "y_test = dataset.test.labels\n",
    "\n",
    "# Printing the dataset shape\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_val:', X_val.shape)\n",
    "print('y_val:', y_val.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "\n",
    "# Displaying an example from the dataset\n",
    "sample = Image.fromarray(255*dataset.train.images[1, :].reshape(28,28))\n",
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.928109090909\n",
      "test accuracy 0.9198\n"
     ]
    }
   ],
   "source": [
    "# Softmax Regression\n",
    "\"\"\"\n",
    "The simplest approach to a classification problem with more than 2 categories is to apply softmax\n",
    "regression. Since softmax regression is essentially a single-layer neural network, it is expected\n",
    "to perform poorly. \n",
    "\"\"\"\n",
    "# Creating and fitting the logistic regression model to the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Printing the accuracy on the training set\n",
    "print('training accuracy', classifier.score(X_train, y_train))\n",
    "\n",
    "# Printing the accuracy on the test set\n",
    "print('test accuracy', classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.92\n",
      "test accuracy 0.9126\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine with Gaussian Kernel\n",
    "\"\"\"\n",
    "The SVM classifier with a Gaussian kernel works well for most classification problems when there isn't\n",
    "much data, however if the training set is very large, training the model can take very long. That is \n",
    "why for this problem we train on a subset of the training set.\n",
    "\"\"\"\n",
    "# Obtaining a subset of the training set\n",
    "X_train_sample, y_train_sample = dataset.train.next_batch(5000)\n",
    "\n",
    "# Creating and fitting the SVM model to the training subset\n",
    "from sklearn import svm\n",
    "classifier = svm.SVC(kernel = 'rbf', decision_function_shape='ovr')\n",
    "classifier.fit(X_train_sample, y_train_sample) \n",
    "\n",
    "# Printing the accuracy on the training subset\n",
    "print('training accuracy', classifier.score(X_train_sample, y_train_sample))\n",
    "\n",
    "# Printing the accuracy on the test set\n",
    "print('test accuracy', classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "X_train: (55000, 784)\n",
      "y_train: (55000, 10)\n",
      "X_val: (5000, 784)\n",
      "y_val: (5000, 10)\n",
      "X_test: (10000, 784)\n",
      "y_test: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For the remaining classifiers, the label needs to be one-hot encoded so in this section we import the \n",
    "dataset again but with one-hot encoding enabled.\n",
    "\"\"\"\n",
    "# Importing the dataset (one-hot encoded)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "dataset = input_data.read_data_sets(\"Datasets/MNIST/\", one_hot=True)\n",
    "\n",
    "X_train = dataset.train.images\n",
    "y_train = dataset.train.labels\n",
    "X_val = dataset.validation.images\n",
    "y_val = dataset.validation.labels\n",
    "X_test = dataset.test.images\n",
    "y_test = dataset.test.labels\n",
    "\n",
    "# Printing the dataset shape\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_val:', X_val.shape)\n",
    "print('y_val:', y_val.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting Datasets/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 3s 49us/step - loss: 0.7748 - acc: 0.7691\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.3197 - acc: 0.9079\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.2648 - acc: 0.9242\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.2257 - acc: 0.9346\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.1973 - acc: 0.9435\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.1780 - acc: 0.9482\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.1623 - acc: 0.9525\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.1502 - acc: 0.9563\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.1407 - acc: 0.9585\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.1321 - acc: 0.9620\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.1246 - acc: 0.9637\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.1186 - acc: 0.9652\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.1114 - acc: 0.9675\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.1049 - acc: 0.9692\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.1000 - acc: 0.9704\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0965 - acc: 0.9717\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0910 - acc: 0.9737\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0865 - acc: 0.9745\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0823 - acc: 0.9751\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0786 - acc: 0.9767\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0743 - acc: 0.9779\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0708 - acc: 0.9783\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0680 - acc: 0.9791\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0649 - acc: 0.9802\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0613 - acc: 0.9814\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0602 - acc: 0.9817\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0566 - acc: 0.9825\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0529 - acc: 0.9841\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0514 - acc: 0.9843\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0504 - acc: 0.9847\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0473 - acc: 0.9858\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0447 - acc: 0.9864\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0425 - acc: 0.9868\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0422 - acc: 0.9869\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0389 - acc: 0.9879\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0383 - acc: 0.9883\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0353 - acc: 0.9890\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0338 - acc: 0.9897\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0317 - acc: 0.9905\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0313 - acc: 0.9900\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0290 - acc: 0.9909\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0282 - acc: 0.9913\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0277 - acc: 0.9916\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0249 - acc: 0.9925\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0237 - acc: 0.9929\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0234 - acc: 0.9930\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0210 - acc: 0.9938\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0208 - acc: 0.9934\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0196 - acc: 0.9939\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0208 - acc: 0.9934\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0166 - acc: 0.9951\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0176 - acc: 0.9947\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0162 - acc: 0.9953\n",
      "Epoch 54/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0146 - acc: 0.9959\n",
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0153 - acc: 0.9954\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0151 - acc: 0.9953\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0139 - acc: 0.9957\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0125 - acc: 0.9963\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0114 - acc: 0.9968\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0111 - acc: 0.9968\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0141 - acc: 0.9955\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0114 - acc: 0.9967\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0117 - acc: 0.9962\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0104 - acc: 0.9972\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0104 - acc: 0.9970\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0078 - acc: 0.9981\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0081 - acc: 0.9977\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0110 - acc: 0.9965\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0085 - acc: 0.9976\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0074 - acc: 0.9981\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0075 - acc: 0.9980\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0088 - acc: 0.9974\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0104 - acc: 0.9965\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0077 - acc: 0.9977\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0074 - acc: 0.9980\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0097 - acc: 0.9969\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0047 - acc: 0.9989\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0027 - acc: 0.9997\n",
      "Epoch 79/100\n",
      "55000/55000 [==============================] - 2s 43us/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 80/100\n",
      "55000/55000 [==============================] - 2s 43us/step - loss: 0.0191 - acc: 0.9942\n",
      "Epoch 81/100\n",
      "55000/55000 [==============================] - 2s 43us/step - loss: 0.0091 - acc: 0.9970\n",
      "Epoch 82/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0039 - acc: 0.9992\n",
      "Epoch 83/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 84/100\n",
      "55000/55000 [==============================] - 2s 43us/step - loss: 0.0069 - acc: 0.9980\n",
      "Epoch 85/100\n",
      "55000/55000 [==============================] - 2s 43us/step - loss: 0.0089 - acc: 0.9971\n",
      "Epoch 86/100\n",
      "55000/55000 [==============================] - 2s 43us/step - loss: 0.0049 - acc: 0.9987\n",
      "Epoch 87/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0024 - acc: 0.9997\n",
      "Epoch 88/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0067 - acc: 0.9982\n",
      "Epoch 89/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0109 - acc: 0.9962\n",
      "Epoch 90/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0051 - acc: 0.9986\n",
      "Epoch 91/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0026 - acc: 0.9996\n",
      "Epoch 92/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0083 - acc: 0.9972\n",
      "Epoch 93/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0044 - acc: 0.9988\n",
      "Epoch 94/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0049 - acc: 0.9987\n",
      "Epoch 95/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0028 - acc: 0.9994\n",
      "Epoch 96/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0056 - acc: 0.9983\n",
      "Epoch 97/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0123 - acc: 0.9959\n",
      "Epoch 98/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0034 - acc: 0.9991\n",
      "Epoch 99/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 100/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.0015 - acc: 0.9999\n",
      "55000/55000 [==============================] - 3s 54us/step\n",
      "training accuracy 0.999981818182\n",
      "10000/10000 [==============================] - 1s 53us/step\n",
      "test accuracy 0.967\n"
     ]
    }
   ],
   "source": [
    "# 3-Layer Standard Neural Network (Multilayer Perceptron)\n",
    "\"\"\"\n",
    "A 3-layer neural network, although not deep, has enough layers to outperform traditional Machine\n",
    "Learning algorithms. These extra layers allow the network to learn more complex features that can \n",
    "be useful for classification. \n",
    "\"\"\"\n",
    "# Importing the libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Creating and fitting the 3-layer neural network to the training set\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 32, kernel_initializer = 'uniform', input_dim = 784, activation = 'relu'))\n",
    "classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.fit(X_train, y_train, batch_size = 128, epochs = 100)\n",
    "\n",
    "# Printing the accuracy on the training subset\n",
    "print('training accuracy', classifier.evaluate(X_train, y_train)[1])\n",
    "\n",
    "# Printing the accuracy on the test set\n",
    "print('test accuracy', classifier.evaluate(X_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 4s 71us/step - loss: 1.7412 - acc: 0.3098\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.9730 - acc: 0.6485\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.6444 - acc: 0.8006\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.4789 - acc: 0.8650\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.3849 - acc: 0.8942\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.3252 - acc: 0.9108\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.2837 - acc: 0.9227\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.2554 - acc: 0.9312\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.2337 - acc: 0.9368\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.2136 - acc: 0.9422\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.2007 - acc: 0.9461\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.1884 - acc: 0.9501\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.1713 - acc: 0.9545\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.1692 - acc: 0.9551\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.1617 - acc: 0.9579\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.1525 - acc: 0.9600\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.1429 - acc: 0.9628\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.1371 - acc: 0.9642\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.1318 - acc: 0.9649\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.1319 - acc: 0.9658\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.1235 - acc: 0.9675\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 3s 61us/step - loss: 0.1169 - acc: 0.9691\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.1121 - acc: 0.9696\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.1126 - acc: 0.9700\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.1063 - acc: 0.9720\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.1030 - acc: 0.9731\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0976 - acc: 0.9753\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.1009 - acc: 0.9736\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0969 - acc: 0.9747\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0912 - acc: 0.9761\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0880 - acc: 0.9769\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0833 - acc: 0.9783\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0815 - acc: 0.9786\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0798 - acc: 0.9796\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0830 - acc: 0.9780\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0724 - acc: 0.9813\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0673 - acc: 0.9824\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0675 - acc: 0.9828\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0717 - acc: 0.9807\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0620 - acc: 0.9837\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0634 - acc: 0.9830\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0632 - acc: 0.9829\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0641 - acc: 0.9831\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0567 - acc: 0.9847\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0534 - acc: 0.9856\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0552 - acc: 0.9854\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0555 - acc: 0.9845\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0513 - acc: 0.9860\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0507 - acc: 0.9864\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0498 - acc: 0.9865\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0499 - acc: 0.9864\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0453 - acc: 0.9873\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0460 - acc: 0.9873\n",
      "Epoch 54/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0429 - acc: 0.9882\n",
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0438 - acc: 0.9877\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0447 - acc: 0.9881\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0434 - acc: 0.9886\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0386 - acc: 0.9896\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0385 - acc: 0.9896\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0385 - acc: 0.9898\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0380 - acc: 0.9898\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0367 - acc: 0.9898\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0423 - acc: 0.9878\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0355 - acc: 0.9904\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0331 - acc: 0.9909\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0339 - acc: 0.9909\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0332 - acc: 0.9910\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0331 - acc: 0.9911\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0314 - acc: 0.9914\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0318 - acc: 0.9918\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0288 - acc: 0.9921\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0323 - acc: 0.9912\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0316 - acc: 0.9914\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0253 - acc: 0.9932\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0308 - acc: 0.9916\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0316 - acc: 0.9914\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 3s 62us/step - loss: 0.0260 - acc: 0.9928\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0262 - acc: 0.9931\n",
      "Epoch 79/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0257 - acc: 0.9931\n",
      "Epoch 80/100\n",
      "55000/55000 [==============================] - 3s 61us/step - loss: 0.0311 - acc: 0.9914\n",
      "Epoch 81/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0253 - acc: 0.9935\n",
      "Epoch 82/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0236 - acc: 0.9934\n",
      "Epoch 83/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0263 - acc: 0.9932\n",
      "Epoch 84/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0224 - acc: 0.9939\n",
      "Epoch 85/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0244 - acc: 0.9933\n",
      "Epoch 86/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0296 - acc: 0.9915\n",
      "Epoch 87/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0221 - acc: 0.9942\n",
      "Epoch 88/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0228 - acc: 0.9939\n",
      "Epoch 89/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0223 - acc: 0.9943\n",
      "Epoch 90/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0214 - acc: 0.9947\n",
      "Epoch 91/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0209 - acc: 0.9944\n",
      "Epoch 92/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0233 - acc: 0.9937\n",
      "Epoch 93/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0212 - acc: 0.9943\n",
      "Epoch 94/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0195 - acc: 0.9949\n",
      "Epoch 95/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0191 - acc: 0.9946\n",
      "Epoch 96/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0195 - acc: 0.9947\n",
      "Epoch 97/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0222 - acc: 0.9939\n",
      "Epoch 98/100\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0202 - acc: 0.9949\n",
      "Epoch 99/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0241 - acc: 0.9938\n",
      "Epoch 100/100\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0220 - acc: 0.9941\n",
      "55000/55000 [==============================] - 3s 61us/step\n",
      "training accuracy 0.996418181818\n",
      "10000/10000 [==============================] - 1s 60us/step\n",
      "test accuracy 0.965\n"
     ]
    }
   ],
   "source": [
    "# 8-Layer Standard Neural Network\n",
    "\"\"\"\n",
    "An 8-layer neural network is considered a deep network. Because it has more layers it should be able to\n",
    "learn even more complex features that can be useful for classification. \n",
    "\"\"\"\n",
    "# Importing the libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Creating and fitting the 8-layer neural network to the training set\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 32, kernel_initializer = 'uniform', input_dim = 784, activation = 'relu'))\n",
    "classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.fit(X_train, y_train, batch_size = 128, epochs = 100)\n",
    "\n",
    "# Printing the accuracy on the training subset\n",
    "print('training accuracy', classifier.evaluate(X_train, y_train)[1])\n",
    "\n",
    "# Printing the accuracy on the test set\n",
    "print('test accuracy', classifier.evaluate(X_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 51s 933us/step - loss: 0.2309 - acc: 0.9337\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 4s 75us/step - loss: 0.0675 - acc: 0.9802\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 4s 75us/step - loss: 0.0462 - acc: 0.9859\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 4s 74us/step - loss: 0.0349 - acc: 0.9896\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 4s 75us/step - loss: 0.0250 - acc: 0.9924\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 4s 75us/step - loss: 0.0202 - acc: 0.9940\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 4s 75us/step - loss: 0.0156 - acc: 0.9952\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 4s 75us/step - loss: 0.0111 - acc: 0.9967\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 5s 97us/step - loss: 0.0082 - acc: 0.9976\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 6s 116us/step - loss: 0.0069 - acc: 0.9979\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 7s 127us/step - loss: 0.0050 - acc: 0.9988\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 7s 119us/step - loss: 0.0062 - acc: 0.9980\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 5s 87us/step - loss: 0.0053 - acc: 0.9983\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 5s 92us/step - loss: 0.0047 - acc: 0.9986\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 7s 129us/step - loss: 0.0033 - acc: 0.9991\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 7s 119us/step - loss: 0.0034 - acc: 0.9991\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 8s 138us/step - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 7s 122us/step - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 5s 93us/step - loss: 0.0041 - acc: 0.9986\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 5s 91us/step - loss: 0.0042 - acc: 0.9987\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 7s 118us/step - loss: 4.6601e-04 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 7s 120us/step - loss: 1.6240e-04 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 7s 124us/step - loss: 7.4399e-05 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 6s 108us/step - loss: 5.1229e-05 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 6s 116us/step - loss: 4.0854e-05 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 5s 94us/step - loss: 3.2487e-05 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 4s 80us/step - loss: 2.6740e-05 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 7s 121us/step - loss: 2.2089e-05 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 7s 122us/step - loss: 1.8281e-05 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 7s 122us/step - loss: 1.5461e-05 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 6s 115us/step - loss: 1.3981e-05 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 7s 120us/step - loss: 1.0243e-05 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 7s 127us/step - loss: 0.0139 - acc: 0.9957\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 7s 126us/step - loss: 0.0028 - acc: 0.9989\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 7s 124us/step - loss: 4.0999e-04 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 7s 119us/step - loss: 9.4134e-05 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 6s 118us/step - loss: 4.8707e-05 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 7s 123us/step - loss: 3.6626e-05 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 7s 123us/step - loss: 2.8801e-05 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 6s 118us/step - loss: 2.2906e-05 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 7s 126us/step - loss: 1.8746e-05 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 7s 122us/step - loss: 1.5135e-05 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 7s 125us/step - loss: 1.2403e-05 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 7s 122us/step - loss: 1.0322e-05 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 7s 126us/step - loss: 8.3874e-06 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 7s 122us/step - loss: 6.8357e-06 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 7s 121us/step - loss: 5.7282e-06 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 7s 121us/step - loss: 4.6814e-06 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 7s 126us/step - loss: 3.7987e-06 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 7s 127us/step - loss: 3.0816e-06 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 7s 125us/step - loss: 2.5832e-06 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 7s 123us/step - loss: 2.1734e-06 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 7s 130us/step - loss: 1.8545e-06 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "55000/55000 [==============================] - 7s 121us/step - loss: 1.5469e-06 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 6s 116us/step - loss: 1.2155e-06 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 7s 122us/step - loss: 1.0017e-06 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 7s 122us/step - loss: 8.2563e-07 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 7s 122us/step - loss: 0.0092 - acc: 0.9974\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 7s 119us/step - loss: 0.0041 - acc: 0.9986\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 7s 118us/step - loss: 5.2766e-04 - acc: 0.9999\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 7s 120us/step - loss: 8.2697e-05 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 6s 118us/step - loss: 3.7133e-05 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 6s 118us/step - loss: 2.6729e-05 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 6s 115us/step - loss: 2.0422e-05 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 6s 109us/step - loss: 1.6059e-05 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 7s 119us/step - loss: 1.2850e-05 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 6s 114us/step - loss: 1.0316e-05 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 6s 109us/step - loss: 8.2934e-06 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 6s 116us/step - loss: 6.7318e-06 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 6s 109us/step - loss: 5.4734e-06 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 6s 109us/step - loss: 4.4269e-06 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 6s 109us/step - loss: 3.5921e-06 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 6s 109us/step - loss: 2.9450e-06 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 5s 84us/step - loss: 2.4024e-06 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 4s 74us/step - loss: 1.9842e-06 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 5s 85us/step - loss: 1.6308e-06 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 4s 81us/step - loss: 1.3624e-06 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 5s 87us/step - loss: 1.1306e-06 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "55000/55000 [==============================] - 4s 73us/step - loss: 9.4138e-07 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "55000/55000 [==============================] - 4s 73us/step - loss: 7.8776e-07 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "55000/55000 [==============================] - 4s 77us/step - loss: 6.7349e-07 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "55000/55000 [==============================] - 5s 85us/step - loss: 5.6386e-07 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "55000/55000 [==============================] - 4s 77us/step - loss: 4.8957e-07 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "55000/55000 [==============================] - 4s 75us/step - loss: 4.1476e-07 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "55000/55000 [==============================] - 4s 75us/step - loss: 3.6048e-07 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "55000/55000 [==============================] - 4s 76us/step - loss: 3.1706e-07 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "55000/55000 [==============================] - 4s 76us/step - loss: 2.8012e-07 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "55000/55000 [==============================] - 5s 86us/step - loss: 2.4806e-07 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "55000/55000 [==============================] - 5s 88us/step - loss: 2.2437e-07 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "55000/55000 [==============================] - 4s 79us/step - loss: 2.0585e-07 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "55000/55000 [==============================] - 4s 81us/step - loss: 1.9122e-07 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "55000/55000 [==============================] - 4s 76us/step - loss: 1.7624e-07 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "55000/55000 [==============================] - 4s 77us/step - loss: 1.6490e-07 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "55000/55000 [==============================] - 4s 77us/step - loss: 1.5585e-07 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "55000/55000 [==============================] - 4s 76us/step - loss: 1.4828e-07 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "55000/55000 [==============================] - 4s 75us/step - loss: 1.4185e-07 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "55000/55000 [==============================] - 4s 76us/step - loss: 1.3760e-07 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "55000/55000 [==============================] - 4s 75us/step - loss: 1.3324e-07 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "55000/55000 [==============================] - 4s 76us/step - loss: 1.3000e-07 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "55000/55000 [==============================] - 4s 76us/step - loss: 1.2778e-07 - acc: 1.0000\n",
      "55000/55000 [==============================] - 7s 124us/step\n",
      "training accuracy 1.0\n",
      "10000/10000 [==============================] - 1s 137us/step\n",
      "test accuracy 0.9892\n"
     ]
    }
   ],
   "source": [
    "# 3-layer Convolutional Network\n",
    "\"\"\"\n",
    "A Convolutional network performs much better than standard neural networks when it comes to computer \n",
    "vision tasks. This is because it tries to learn features or rather feature detectors from groups of \n",
    "pixels, taking into account the shape of the image. The parameters learned come in the form of filters. \n",
    "There are also considerable fewer parameters, which result from parameter sharing and sparsity of \n",
    "connections. This particular ConvNet has 1 convolutional layer, 1 fully-connected layer, and an output \n",
    "layer.\n",
    "\"\"\"\n",
    "# Importing the libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Reshaping the images to be of shape 28x28x1\n",
    "X_train_image = X_train.reshape( -1, 28, 28, 1)\n",
    "X_val_image = X_val.reshape( -1, 28, 28, 1)\n",
    "X_test_image = X_test.reshape( -1, 28, 28, 1)\n",
    "\n",
    "# Creating and fitting the 3-layer CNN to the training set\n",
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 10, activation = 'softmax'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.fit(X_train_image, y_train, batch_size = 128, epochs = 100)\n",
    "\n",
    "# Printing the accuracy on the training subset\n",
    "print('training accuracy', classifier.evaluate(X_train_image, y_train)[1])\n",
    "\n",
    "# Printing the accuracy on the test set\n",
    "print('test accuracy', classifier.evaluate(X_test_image, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 11s 201us/step - loss: 0.2483 - acc: 0.9240\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 9s 160us/step - loss: 0.0607 - acc: 0.9811\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 9s 159us/step - loss: 0.0440 - acc: 0.9866\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 9s 166us/step - loss: 0.0342 - acc: 0.9894\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 8s 152us/step - loss: 0.0281 - acc: 0.9911\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 8s 151us/step - loss: 0.0244 - acc: 0.9922\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 8s 151us/step - loss: 0.0206 - acc: 0.9934\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.0175 - acc: 0.9941\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 8s 151us/step - loss: 0.0164 - acc: 0.9946\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 8s 151us/step - loss: 0.0143 - acc: 0.9953\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 9s 155us/step - loss: 0.0144 - acc: 0.9955\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 9s 157us/step - loss: 0.0136 - acc: 0.9954\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 9s 159us/step - loss: 0.0126 - acc: 0.9958\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 8s 152us/step - loss: 0.0104 - acc: 0.9965\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 8s 151us/step - loss: 0.0081 - acc: 0.9972\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0108 - acc: 0.9964\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0072 - acc: 0.9978\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0098 - acc: 0.9968\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 0.0084 - acc: 0.9973\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0083 - acc: 0.9975\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0071 - acc: 0.9977\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 8s 152us/step - loss: 0.0064 - acc: 0.9977\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 8s 154us/step - loss: 0.0075 - acc: 0.9976\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 8s 150us/step - loss: 0.0043 - acc: 0.9985\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0061 - acc: 0.9980\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 8s 151us/step - loss: 0.0055 - acc: 0.9982\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 9s 155us/step - loss: 0.0069 - acc: 0.9978\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 8s 151us/step - loss: 0.0058 - acc: 0.9983\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 8s 151us/step - loss: 0.0070 - acc: 0.9976\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 8s 153us/step - loss: 0.0042 - acc: 0.9988\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 8s 154us/step - loss: 0.0051 - acc: 0.9985\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 8s 151us/step - loss: 0.0063 - acc: 0.9982\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.0049 - acc: 0.9987\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 8s 154us/step - loss: 0.0021 - acc: 0.9994\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0066 - acc: 0.9981\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.0052 - acc: 0.9985\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.0021 - acc: 0.9994\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 8s 154us/step - loss: 0.0048 - acc: 0.9985\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 8s 150us/step - loss: 0.0034 - acc: 0.9989\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.0061 - acc: 0.9981\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 8s 150us/step - loss: 0.0040 - acc: 0.9989\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0046 - acc: 0.9985\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 0.0034 - acc: 0.9989\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 8.9707e-04 - acc: 0.9998\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 0.0044 - acc: 0.9988\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 0.0031 - acc: 0.9991\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 0.0024 - acc: 0.9993\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 0.0051 - acc: 0.9986\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 8s 151us/step - loss: 0.0040 - acc: 0.9990\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.0041 - acc: 0.9989\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 9s 160us/step - loss: 0.0014 - acc: 0.9996\n",
      "Epoch 54/100\n",
      "55000/55000 [==============================] - 8s 151us/step - loss: 0.0039 - acc: 0.9989\n",
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.0039 - acc: 0.9988\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.0034 - acc: 0.9990\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0022 - acc: 0.9993\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0034 - acc: 0.9990\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0023 - acc: 0.9993\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 8s 150us/step - loss: 0.0041 - acc: 0.9988\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 8s 150us/step - loss: 0.0053 - acc: 0.9984\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.0023 - acc: 0.9994\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.0031 - acc: 0.9993\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0033 - acc: 0.9991\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 0.0020 - acc: 0.9994\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 5.3509e-04 - acc: 0.9999\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0043 - acc: 0.9988\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 8.3183e-04 - acc: 0.9998\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 8s 145us/step - loss: 8.0905e-04 - acc: 0.9999\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 8s 145us/step - loss: 0.0042 - acc: 0.9990\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 8s 145us/step - loss: 0.0046 - acc: 0.9987\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 8s 144us/step - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 79/100\n",
      "55000/55000 [==============================] - 8s 144us/step - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 80/100\n",
      "55000/55000 [==============================] - 8s 144us/step - loss: 0.0048 - acc: 0.9988\n",
      "Epoch 81/100\n",
      "55000/55000 [==============================] - 8s 145us/step - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 82/100\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 83/100\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 84/100\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0041 - acc: 0.9989\n",
      "Epoch 85/100\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 86/100\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 87/100\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 0.0021 - acc: 0.9995\n",
      "Epoch 88/100\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0061 - acc: 0.9985\n",
      "Epoch 89/100\n",
      "55000/55000 [==============================] - 9s 163us/step - loss: 0.0022 - acc: 0.9994\n",
      "Epoch 90/100\n",
      "55000/55000 [==============================] - 9s 159us/step - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 91/100\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 9.8378e-04 - acc: 0.9997\n",
      "Epoch 92/100\n",
      "55000/55000 [==============================] - 8s 151us/step - loss: 0.0024 - acc: 0.9995\n",
      "Epoch 93/100\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.0054 - acc: 0.9987\n",
      "Epoch 94/100\n",
      "55000/55000 [==============================] - 9s 160us/step - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 95/100\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 96/100\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 8.7639e-04 - acc: 0.9998\n",
      "Epoch 97/100\n",
      "55000/55000 [==============================] - 8s 145us/step - loss: 0.0040 - acc: 0.9988\n",
      "Epoch 98/100\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 99/100\n",
      "55000/55000 [==============================] - 8s 152us/step - loss: 0.0021 - acc: 0.9994\n",
      "Epoch 100/100\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 9.3337e-04 - acc: 0.9998\n",
      "55000/55000 [==============================] - 7s 120us/step\n",
      "training accuracy 0.999945454545\n",
      "10000/10000 [==============================] - 1s 111us/step\n",
      "test accuracy 0.9929\n"
     ]
    }
   ],
   "source": [
    "# 8-layer Convolutional Network\n",
    "\"\"\"\n",
    "The deeper a Convolutional network is, the more complex features it can learn. These complex features\n",
    "may be useful in classifying an image. This particular ConvNet has 5 convolutional layer, \n",
    "2 fully-connected layer, and an output layer.\n",
    "\"\"\"\n",
    "# Importing the libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Reshaping the images to be of shape 28x28x1\n",
    "X_train_image = X_train.reshape( -1, 28, 28, 1)\n",
    "X_val_image = X_val.reshape( -1, 28, 28, 1)\n",
    "X_test_image = X_test.reshape( -1, 28, 28, 1)\n",
    "\n",
    "# Creating and fitting the 8-layer CNN to the training set\n",
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 10, activation = 'softmax'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.fit(X_train_image, y_train, batch_size = 128, epochs = 100)\n",
    "\n",
    "# Printing the accuracy on the training subset\n",
    "print('training accuracy', classifier.evaluate(X_train_image, y_train)[1])\n",
    "\n",
    "# Printing the accuracy on the test set\n",
    "print('test accuracy', classifier.evaluate(X_test_image, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 127s 2ms/step - loss: 0.1323 - acc: 0.9593\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 125s 2ms/step - loss: 0.0405 - acc: 0.9879\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 125s 2ms/step - loss: 0.0271 - acc: 0.9912\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 125s 2ms/step - loss: 0.0186 - acc: 0.9943\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 124s 2ms/step - loss: 0.0137 - acc: 0.9955\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 124s 2ms/step - loss: 0.0121 - acc: 0.9959\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 124s 2ms/step - loss: 0.0092 - acc: 0.9969\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 124s 2ms/step - loss: 0.0075 - acc: 0.9973\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 125s 2ms/step - loss: 0.0071 - acc: 0.9977\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 0.0072 - acc: 0.9976\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 124s 2ms/step - loss: 0.0051 - acc: 0.9982\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 125s 2ms/step - loss: 0.0045 - acc: 0.9986\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 124s 2ms/step - loss: 0.0046 - acc: 0.9985\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 0.0047 - acc: 0.9985\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 0.0045 - acc: 0.9989\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 0.0038 - acc: 0.9988\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0052 - acc: 0.9985\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0030 - acc: 0.9992\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0045 - acc: 0.9987\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0023 - acc: 0.9994\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0037 - acc: 0.9991\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0028 - acc: 0.9991\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0027 - acc: 0.9992\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0018 - acc: 0.9995\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0040 - acc: 0.9993\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0021 - acc: 0.9996\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0049 - acc: 0.9990\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0016 - acc: 0.9995\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 5.6535e-04 - acc: 0.9999\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 0.0051 - acc: 0.9989\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 5.5073e-04 - acc: 0.9999\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 3.2505e-04 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9412e-04 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9385e-04 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9369e-04 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9358e-04 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9349e-04 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9343e-04 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9338e-04 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9334e-04 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9331e-04 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9328e-04 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9326e-04 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 124s 2ms/step - loss: 2.9325e-04 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9323e-04 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9322e-04 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9321e-04 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9320e-04 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9320e-04 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9319e-04 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9319e-04 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9319e-04 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9319e-04 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 121s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 121s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "55000/55000 [==============================] - 125s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "55000/55000 [==============================] - 124s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "55000/55000 [==============================] - 123s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "55000/55000 [==============================] - 125s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "55000/55000 [==============================] - 125s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "55000/55000 [==============================] - 125s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "55000/55000 [==============================] - 122s 2ms/step - loss: 2.9318e-04 - acc: 1.0000\n",
      "55000/55000 [==============================] - 77s 1ms/step\n",
      "training accuracy 0.999981818182\n",
      "10000/10000 [==============================] - 14s 1ms/step\n",
      "test accuracy 0.9908\n"
     ]
    }
   ],
   "source": [
    "# Inception Network\n",
    "\"\"\"\n",
    "An inception network lets the network choose which filters to use when classifying an image. It is \n",
    "composed of many inception blocks where an inception block consists of many different convolutions \n",
    "with different filters concatenated into one. The network below consists of 3 inception blocks. \n",
    "\"\"\"\n",
    "# Importing the libraries\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Reshaping the images to be of shape 28x28x1\n",
    "X_train_image = X_train.reshape( -1, 28, 28, 1)\n",
    "X_val_image = X_val.reshape( -1, 28, 28, 1)\n",
    "X_test_image = X_test.reshape( -1, 28, 28, 1)\n",
    "\n",
    "# Defining the Inception block\n",
    "def inception_block(input):\n",
    "    branch_1 = Conv2D(64, (1, 1), activation = 'relu', padding = 'same')(input)\n",
    "    branch_2 = Conv2D(96, (1, 1), activation = 'relu', padding = 'same')(input)\n",
    "    branch_2 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same')(branch_2)\n",
    "    branch_3 = Conv2D(16, (1, 1), activation = 'relu', padding = 'same')(input)\n",
    "    branch_3 = Conv2D(32, (5, 5), activation = 'relu', padding = 'same')(branch_3)\n",
    "    branch_4 = MaxPooling2D(pool_size = (3, 3), strides = (1, 1), padding = 'same')(input)\n",
    "    branch_4 = Conv2D(32, (1, 1), activation = 'relu', padding = 'same')(branch_4)\n",
    "    output = Concatenate(axis=-1)([branch_1, branch_2, branch_3, branch_4])\n",
    "    return output\n",
    "\n",
    "# Creating and fitting the Inception Network to the training set\n",
    "X_input = Input((28, 28, 1))\n",
    "X = inception_block(X_input)\n",
    "X = inception_block(X)\n",
    "X = inception_block(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(units=10, kernel_initializer = 'glorot_uniform', activation='softmax')(X)\n",
    "\n",
    "classifier = Model(inputs = X_input, outputs = X)\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "classifier.fit(X_train_image, y_train, batch_size = 128, epochs = 100)\n",
    "\n",
    "# Printing the accuracy on the training subset\n",
    "print('training accuracy', classifier.evaluate(X_train_image, y_train)[1])\n",
    "\n",
    "# Printing the accuracy on the test set\n",
    "print('test accuracy', classifier.evaluate(X_test_image, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 144s 3ms/step - loss: 0.4986 - acc: 0.8562\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 126s 2ms/step - loss: 0.1074 - acc: 0.9661\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 126s 2ms/step - loss: 0.0647 - acc: 0.9795\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 126s 2ms/step - loss: 0.0519 - acc: 0.9833\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 126s 2ms/step - loss: 0.0659 - acc: 0.9807\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 126s 2ms/step - loss: 0.0526 - acc: 0.9841\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 126s 2ms/step - loss: 0.0286 - acc: 0.9913\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 121s 2ms/step - loss: 0.0256 - acc: 0.9915\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0421 - acc: 0.9874\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0363 - acc: 0.9888\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0436 - acc: 0.9877\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0312 - acc: 0.9905\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0240 - acc: 0.9925\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0241 - acc: 0.9928\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0225 - acc: 0.9933\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0713 - acc: 0.9805\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0324 - acc: 0.9906\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0220 - acc: 0.9931\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0208 - acc: 0.9934\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0214 - acc: 0.9932\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0218 - acc: 0.9934\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0177 - acc: 0.9946\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0202 - acc: 0.9940\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0188 - acc: 0.9947\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0513 - acc: 0.9852\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0199 - acc: 0.9940\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0188 - acc: 0.9941\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0131 - acc: 0.9961\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0136 - acc: 0.9959\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0150 - acc: 0.9955\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0131 - acc: 0.9961\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0144 - acc: 0.9959\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0135 - acc: 0.9959\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0124 - acc: 0.9965\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0118 - acc: 0.9963\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0105 - acc: 0.9969\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0101 - acc: 0.9970\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0133 - acc: 0.9960\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0089 - acc: 0.9973\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0100 - acc: 0.9971\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0105 - acc: 0.9965\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0084 - acc: 0.9974\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0088 - acc: 0.9976\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0071 - acc: 0.9979\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0076 - acc: 0.9975\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0092 - acc: 0.9974\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0068 - acc: 0.9980\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0702 - acc: 0.9843\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0304 - acc: 0.9908\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0122 - acc: 0.9963\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0071 - acc: 0.9978\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0039 - acc: 0.9987\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0036 - acc: 0.9989\n",
      "Epoch 54/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0031 - acc: 0.9988\n",
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0273 - acc: 0.9931\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0223 - acc: 0.9929\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0064 - acc: 0.9979\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0031 - acc: 0.9990\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0040 - acc: 0.9988\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0043 - acc: 0.9987\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0035 - acc: 0.9990\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0035 - acc: 0.9989\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0079 - acc: 0.9975\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0044 - acc: 0.9987\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0050 - acc: 0.9982\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0043 - acc: 0.9988\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0036 - acc: 0.9987\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0065 - acc: 0.9980\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0033 - acc: 0.9990\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0419 - acc: 0.9928\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0048 - acc: 0.9987\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0044 - acc: 0.9987\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0042 - acc: 0.9987\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0055 - acc: 0.9984\n",
      "Epoch 79/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0044 - acc: 0.9987\n",
      "Epoch 80/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 81/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0067 - acc: 0.9981\n",
      "Epoch 82/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0041 - acc: 0.9988\n",
      "Epoch 83/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0038 - acc: 0.9988\n",
      "Epoch 84/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0135 - acc: 0.9966\n",
      "Epoch 85/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0031 - acc: 0.9992\n",
      "Epoch 86/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 87/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0047 - acc: 0.9987\n",
      "Epoch 88/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0035 - acc: 0.9990\n",
      "Epoch 89/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 90/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0047 - acc: 0.9987\n",
      "Epoch 91/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0025 - acc: 0.9992\n",
      "Epoch 92/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0034 - acc: 0.9990\n",
      "Epoch 93/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 94/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0048 - acc: 0.9988\n",
      "Epoch 95/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0034 - acc: 0.9989\n",
      "Epoch 96/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0032 - acc: 0.9991\n",
      "Epoch 97/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0039 - acc: 0.9988\n",
      "Epoch 98/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0041 - acc: 0.9988\n",
      "Epoch 99/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 100/100\n",
      "55000/55000 [==============================] - 120s 2ms/step - loss: 0.0024 - acc: 0.9994\n",
      "55000/55000 [==============================] - 61s 1ms/step\n",
      "training accuracy 0.999181818182\n",
      "10000/10000 [==============================] - 11s 1ms/step\n",
      "test accuracy 0.992\n"
     ]
    }
   ],
   "source": [
    "# Residual Network\n",
    "\"\"\"\n",
    "Vanishing/exploding gradients is a common problem that occurs when having a very deep network. Residual\n",
    "networks (ResNets) combined with the use of batch normalization helps resolve this problem. Using a \n",
    "ResNet, we are able to train networks with over 100 layers. Residual networks are made up of a series \n",
    "of residual blocks. These blocks contain a 'skip connection' that allows the gradient to be directly\n",
    "backpropagated to earlier layers. There are 2 main types of residual blocks; they are the identity\n",
    "block (input has same dimension as output) and the convolutional block (input has a different dimension\n",
    "from output). A ResNet is made up of a series of many of these different blocks. This particular Resnet\n",
    "consists of 65 layers.\n",
    "\"\"\"\n",
    "# Importing the libraries\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Add\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "# Reshaping the images to be of shape 28x28x1\n",
    "X_train_image = X_train.reshape( -1, 28, 28, 1)\n",
    "X_val_image = X_val.reshape( -1, 28, 28, 1)\n",
    "X_test_image = X_test.reshape( -1, 28, 28, 1)\n",
    "\n",
    "# Defining the identity block function (output dimension same as input dimension)\n",
    "def identity_block(input, filters, kernel_size):\n",
    "    F1, F2, F3 = filters \n",
    "    output = Conv2D(F1, (1, 1), padding = 'valid')(input)\n",
    "    output = BatchNormalization(axis = -1)(output)\n",
    "    output = Activation('relu')(output)\n",
    "    output = Conv2D(F2, (kernel_size, kernel_size), padding = 'same')(output)\n",
    "    output = BatchNormalization(axis = -1)(output)\n",
    "    output = Activation('relu')(output)\n",
    "    output = Conv2D(F3, (1, 1), padding = 'valid')(output)\n",
    "    output = BatchNormalization(axis = -1)(output)\n",
    "    output = Add()([output, input])\n",
    "    output = Activation('relu')(output)\n",
    "    \n",
    "    return output\n",
    "    \n",
    "# Defining the convolutional block function (output dimension different from input dimension)\n",
    "def convolutional_block(input, filters, kernel_size, strides):\n",
    "    F1, F2, F3 = filters\n",
    "    output = Conv2D(F1, (1, 1), strides = (strides, strides), padding = 'valid')(input)\n",
    "    output = BatchNormalization(axis = -1)(output)\n",
    "    output = Activation('relu')(output)\n",
    "    output = Conv2D(F2, (kernel_size, kernel_size), padding = 'same')(output)\n",
    "    output = BatchNormalization(axis = -1)(output)\n",
    "    output = Activation('relu')(output)\n",
    "    output = Conv2D(F3, (1, 1), padding = 'valid')(output)\n",
    "    output = BatchNormalization(axis = -1)(output)\n",
    "    output_sc = Conv2D(F3, (1, 1), strides = (strides, strides), padding = 'valid')(input)\n",
    "    output_sc = BatchNormalization(axis = -1)(output_sc)\n",
    "    output = Add()([output, output_sc])\n",
    "    output = Activation('relu')(output)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Creating and fitting the Residual Network to the training set\n",
    "X_input = Input((28, 28, 1))\n",
    "X = ZeroPadding2D((2, 2))(X_input)\n",
    "X = Conv2D(32, (3, 3), padding = 'same', strides = (2,2))(X)\n",
    "X = BatchNormalization(axis = -1)(X)\n",
    "X = Activation('relu')(X)\n",
    "X = convolutional_block(X, filters = [32, 32, 128], kernel_size = 3, strides = 1)\n",
    "X = identity_block(X, filters = [32, 32, 128], kernel_size = 3)\n",
    "X = identity_block(X, filters = [32, 32, 128], kernel_size = 3)\n",
    "X = convolutional_block(X, filters = [64, 64, 256], kernel_size = 3, strides = 2)\n",
    "X = identity_block(X, filters = [64, 64, 256], kernel_size = 3)\n",
    "X = identity_block(X, filters = [64, 64, 256], kernel_size = 3)\n",
    "X = identity_block(X, filters = [64, 64, 256], kernel_size = 3)\n",
    "X = convolutional_block(X, filters = [128, 128, 512], kernel_size = 3, strides = 2)\n",
    "X = identity_block(X, filters = [128, 128, 512], kernel_size = 3)\n",
    "X = identity_block(X, filters = [128, 128, 512], kernel_size = 3)\n",
    "X = identity_block(X, filters = [128, 128, 512], kernel_size = 3)\n",
    "X = identity_block(X, filters = [128, 128, 512], kernel_size = 3)\n",
    "X = convolutional_block(X, filters = [256, 256, 1024], kernel_size = 3, strides = 2)\n",
    "X = identity_block(X, filters = [256, 256, 1024], kernel_size = 3)\n",
    "X = identity_block(X, filters = [256, 256, 1024], kernel_size = 3)\n",
    "X = identity_block(X, filters = [256, 256, 1024], kernel_size = 3)\n",
    "X = identity_block(X, filters = [256, 256, 1024], kernel_size = 3)\n",
    "X = identity_block(X, filters = [256, 256, 1024], kernel_size = 3)\n",
    "X = convolutional_block(X, filters = [512, 512, 2048], kernel_size = 3, strides = 2)\n",
    "X = identity_block(X, filters = [512, 512, 2048], kernel_size = 3)\n",
    "X = identity_block(X, filters = [512, 512, 2048], kernel_size = 3)\n",
    "X = Flatten()(X)\n",
    "X = Dense(units=10, kernel_initializer = 'glorot_uniform', activation='softmax')(X)\n",
    "\n",
    "classifier = Model(inputs = X_input, outputs = X)\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "classifier.fit(X_train_image, y_train, batch_size = 128, epochs = 100)\n",
    "\n",
    "# Printing the accuracy on the training subset\n",
    "print('training accuracy', classifier.evaluate(X_train_image, y_train)[1])\n",
    "\n",
    "# Printing the accuracy on the test set\n",
    "print('test accuracy', classifier.evaluate(X_test_image, y_test)[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
